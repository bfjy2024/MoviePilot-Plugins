"""
ç«™ç‚¹è€ƒæ ¸çŠ¶æ€æ’ä»¶
è‡ªåŠ¨è·å–ç«™ç‚¹è€ƒæ ¸æƒ…å†µå¹¶åœ¨ä»ªè¡¨æ¿æ˜¾ç¤º
"""
import re
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional, Tuple

import pytz
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
from lxml import etree

from app.core.config import settings
from app.core.event import eventmanager, Event
from app.db.site_oper import SiteOper
from app.log import logger
from app.plugins import _PluginBase
from app.schemas.types import EventType, NotificationType
from app.utils.http import RequestUtils
from html import unescape


class SiteAssessment(_PluginBase):
    """ç«™ç‚¹è€ƒæ ¸çŠ¶æ€æ’ä»¶"""

    # æ’ä»¶åç§°
    plugin_name = "ç«™ç‚¹è€ƒæ ¸çŠ¶æ€"
    # æ’ä»¶æè¿°
    plugin_desc = "è‡ªåŠ¨è·å–ç«™ç‚¹è€ƒæ ¸æƒ…å†µå¹¶åœ¨ä»ªè¡¨æ¿æ˜¾ç¤ºï¼Œæ”¯æŒè€ƒæ ¸ä¸´è¿‘æ—¶å‘é€é€šçŸ¥ã€‚"
    # æ’ä»¶å›¾æ ‡
    plugin_icon = "https://raw.githubusercontent.com/jxxghp/MoviePilot-Plugins/main/icons/statistic.png"
    # æ’ä»¶ç‰ˆæœ¬
    plugin_version = "2.0"
    # æ’ä»¶ä½œè€…
    plugin_author = "æ¨±èŠ±ä½¬,bfjy"
    # ä½œè€…ä¸»é¡µ
    author_url = "https://bfjy2024.github.io/bfjy"
    # æ’ä»¶é…ç½®é¡¹IDå‰ç¼€
    plugin_config_prefix = "siteassessment_"
    # åŠ è½½é¡ºåº
    plugin_order = 10
    # å¯ä½¿ç”¨çš„ç”¨æˆ·çº§åˆ«
    auth_level = 2

    # ç§æœ‰å±æ€§
    _enabled: bool = False
    _onlyonce: bool = False
    _cron: str = ""
    _notify: bool = False
    _notify_days: int = 3
    _selected_sites: List[int] = []
    _scheduler: Optional[BackgroundScheduler] = None
    _cached_statuses: List[Dict[str, Any]] = []  # ç¼“å­˜çš„è€ƒæ ¸çŠ¶æ€æ•°æ®

    # æ–‡ä»¶å¤§å°å•ä½è½¬æ¢ï¼ˆè½¬ä¸ºå­—èŠ‚ï¼‰
    _SIZE_UNITS: Dict[str, float] = {
        # åè¿›åˆ¶å•ä½
        'B': 1,
        'KB': 1024,
        'MB': 1024 ** 2,
        'GB': 1024 ** 3,
        'TB': 1024 ** 4,
        'PB': 1024 ** 5,
        # äºŒè¿›åˆ¶å•ä½
        'KIB': 1024,
        'MIB': 1024 ** 2,
        'GIB': 1024 ** 3,
        'TIB': 1024 ** 4,
        'PIB': 1024 ** 5,
    }

    # æ—¶é—´å•ä½è½¬æ¢ï¼ˆè½¬ä¸ºå°æ—¶ï¼‰
    _TIME_UNITS: Dict[str, float] = {
        'ç§’': 1 / 3600, 'S': 1 / 3600, 'SEC': 1 / 3600, 'SECOND': 1 / 3600, 'SECONDS': 1 / 3600,
        'åˆ†': 1 / 60, 'M': 1 / 60, 'MIN': 1 / 60, 'MINUTE': 1 / 60, 'MINUTES': 1 / 60, 'åˆ†é’Ÿ': 1 / 60, 'åˆ†é˜': 1 / 60,
        'æ—¶': 1, 'H': 1, 'HR': 1, 'HRS': 1, 'HOUR': 1, 'HOURS': 1, 'å°æ—¶': 1, 'å°æ™‚': 1,
        'å¤©': 24, 'D': 24, 'DAY': 24, 'DAYS': 24, 'æ—¥': 24,
        'å‘¨': 24 * 7, 'W': 24 * 7, 'WEEK': 24 * 7, 'WEEKS': 24 * 7, 'é€±': 24 * 7,
        'æœˆ': 24 * 30, 'MONTH': 24 * 30, 'MONTHS': 24 * 30, 'å€‹æœˆ': 24 * 30,
        'å¹´': 24 * 365, 'Y': 24 * 365, 'YEAR': 24 * 365, 'YEARS': 24 * 365,
    }

    # è€ƒæ ¸ç›¸å…³å…³é”®è¯ï¼ˆç”¨äºè¯†åˆ«è€ƒæ ¸åŒºå—ï¼‰
    _ASSESSMENT_KEYWORDS: Tuple[str, ...] = (
        # ç®€ä½“
        'è€ƒæ ¸', 'æ–°æ‰‹ä»»åŠ¡', 'å…»æˆæœŸ', 'è¯•ç”¨æœŸ', 'è§‚å¯ŸæœŸ', 'æ–°äººä»»åŠ¡',
        'ä¿å·', 'æ´»è·ƒåº¦', 'åšç§ä»»åŠ¡', 'ä¸Šä¼ ä»»åŠ¡', 'é­”åŠ›ä»»åŠ¡',
        'è¯•ç‚¼', 'åˆ†æ”¯ä»»åŠ¡', 'æŒ‘æˆ˜ä»»åŠ¡', 'æˆå°±ä»»åŠ¡',
        # ç¹ä½“
        'é¤ŠæˆæœŸ', 'è©¦ç”¨æœŸ', 'è§€å¯ŸæœŸ', 'æ–°äººä»»å‹™', 'åšç¨®ä»»å‹™', 'ä¸Šå‚³ä»»å‹™', 'é­”åŠ›ä»»å‹™',
        'è©¦ç…‰', 'åˆ†æ”¯ä»»å‹™', 'æŒ‘æˆ°ä»»å‹™', 'æˆå°±ä»»å‹™',
        # è‹±æ–‡
        'assessment', 'probation', 'trial', 'newbie', 'requirement', 'quest', 'mission',
    )

    # è€ƒæ ¸æŒ‡æ ‡åç§°å…³é”®è¯ï¼ˆç”¨äºè¯†åˆ«æŒ‡æ ‡ç±»å‹ï¼‰
    _METRIC_KEYWORDS: Dict[str, Tuple[str, ...]] = {
        'upload': ('ä¸Šä¼ ', 'ä¸Šå‚³', 'upload', 'ä¸Šä¼ é‡', 'ä¸Šå‚³é‡', 'ä¸Šä¼ å¢é‡', 'ä¸Šå‚³å¢é‡'),
        'download': ('ä¸‹è½½', 'ä¸‹è¼‰', 'download', 'ä¸‹è½½é‡', 'ä¸‹è¼‰é‡', 'ä¸‹è½½å¢é‡', 'ä¸‹è¼‰å¢é‡'),
        'ratio': ('åˆ†äº«ç‡', 'åˆ†äº«æ¯”', 'æ¯”ç‡', 'ratio', 'share ratio'),
        'bonus': ('é­”åŠ›', 'ç§¯åˆ†', 'é­”åŠ›å€¼', 'ç©åˆ†', 'bonus', 'points', 'karma', 'credits', 'é­”åŠ›å¢é‡', 'åšç§ç§¯åˆ†', 'åšç¨®ç©åˆ†'),
        'seeding': ('åšç§', 'åšç¨®', 'ä¿ç§', 'ä¿ç¨®', 'seeding', 'seed', 'åšç§é‡', 'åšç¨®é‡'),
        'seedtime': ('åšç§æ—¶é—´', 'åšç¨®æ™‚é–“', 'ä¿ç§æ—¶é—´', 'ä¿ç¨®æ™‚é–“', 'seed time', 'seeding time', 'åšç§æ—¶é•¿', 'åšç¨®æ™‚é•·'),
        'seedsize': ('åšç§ä½“ç§¯', 'åšç¨®é«”ç©', 'ä¿ç§ä½“ç§¯', 'ä¿ç¨®é«”ç©', 'seeding size'),
        'torrents': ('å‘å¸ƒæ•°', 'ç™¼å¸ƒæ•¸', 'å‘ç§æ•°', 'ç™¼ç¨®æ•¸'),
        'invites': ('é‚€è¯·', 'é‚€è«‹', 'invite', 'é‚€è¯·æ•°', 'é‚€è«‹æ•¸'),
    }

    # æœ‰æ•ˆçš„è€ƒæ ¸æŒ‡æ ‡åç§°ï¼ˆç²¾ç¡®åŒ¹é…ï¼Œç”¨äºä¸¥æ ¼æ¨¡å¼ï¼‰
    # æ³¨æ„ï¼šè¿™äº›åç§°å¿…é¡»æ˜¯è€ƒæ ¸ç‰¹æœ‰çš„ï¼Œé¿å…ä¸ç«™ç‚¹ç»Ÿè®¡æ··æ·†
    _VALID_METRIC_NAMES: Tuple[str, ...] = (
        # ä¸Šä¼ ç›¸å…³ï¼ˆè€ƒæ ¸å¸¸ç”¨ï¼‰
        'ä¸Šä¼ é‡', 'ä¸Šå‚³é‡', 'ä¸Šä¼ å¢é‡', 'ä¸Šå‚³å¢é‡',
        # ä¸‹è½½ç›¸å…³ï¼ˆè€ƒæ ¸å¸¸ç”¨ï¼‰
        'ä¸‹è½½é‡', 'ä¸‹è¼‰é‡', 'ä¸‹è½½å¢é‡', 'ä¸‹è¼‰å¢é‡',
        # åˆ†äº«ç‡
        'åˆ†äº«ç‡', 'åˆ†äº«æ¯”',
        # é­”åŠ›/ç§¯åˆ†ï¼ˆè€ƒæ ¸å¸¸ç”¨ï¼‰
        'é­”åŠ›', 'é­”åŠ›å€¼', 'é­”åŠ›å¢é‡',
        'ç§¯åˆ†', 'ç©åˆ†', 'ç§¯åˆ†å¢é‡',
        'åšç§ç§¯åˆ†', 'åšç¨®ç©åˆ†', 'åšç§ç§¯åˆ†å¢é‡',
        # åšç§æ—¶é—´ï¼ˆè€ƒæ ¸å¸¸ç”¨ï¼‰
        'åšç§æ—¶é—´', 'åšç¨®æ™‚é–“', 'åšç§æ—¶é•¿', 'åšç¨®æ™‚é•·',
        'ä¿ç§æ—¶é—´', 'ä¿ç¨®æ™‚é–“',
        # åšç§ä½“ç§¯
        'åšç§ä½“ç§¯', 'åšç¨®é«”ç©', 'ä¿ç§ä½“ç§¯', 'ä¿ç¨®é«”ç©',
    )

    # æ— æ•ˆæŒ‡æ ‡åç§°ï¼ˆé»‘åå•ï¼Œç”¨äºæ’é™¤ï¼‰
    _INVALID_METRIC_PATTERNS: Tuple[str, ...] = (
        # ç«™ç‚¹ç»Ÿè®¡ä¿¡æ¯
        'æ³¨å†Œç”¨æˆ·', 'è¨»å†Šç”¨æˆ¶', 'è®¿é—®ç”¨æˆ·', 'è¨ªå•ç”¨æˆ¶', 'å½“å‰è®¿é—®', 'ç•¶å‰è¨ªå•',
        'ç§å­æ€»', 'ç¨®å­ç¸½', 'æ€»ä¸Šä¼ ', 'ç¸½ä¸Šå‚³', 'æ€»ä¸‹è½½', 'ç¸½ä¸‹è¼‰', 'æ€»æ•°æ®', 'ç¸½æ•¸æ“š',
        'è´µå®¾', 'è²´è³“', 'è¢«è­¦å‘Š', 'è¢«ç¦', 'ç”·ç”Ÿ', 'å¥³ç”Ÿ', 'æ–­ç§', 'æ–·ç¨®',
        'åŒä¼´', 'tracker', 'Tracker',
        # ç”¨æˆ·ç­‰çº§
        'Peasant', 'User', 'Power User', 'Elite', 'Crazy', 'Insane', 'Veteran', 'Extreme', 'Ultimate', 'Master',
        # ç‰ˆå—/å¸–å­
        'ç‰ˆå—', 'ç‰ˆå¡Š', 'Feedback', 'Appeal', 'Record',
        # ç§å­æ ‡é¢˜ç‰¹å¾
        '1080p', '2160p', '4K', 'BluRay', 'Blu-ray', 'WEB-DL', 'REMUX', 'HDR', 'DoVi',
        'H.264', 'H.265', 'HEVC', 'AVC', 'DTS', 'AAC', 'FLAC', 'Atmos',
        'å¯¼æ¼”', 'ä¸»æ¼”', 'ç±»åˆ«', 'åœ‹èª', 'å›½è¯­', 'ä¸­å­—', 'å­—å¹•',
        # æŠ•ç¥¨é€‰é¡¹
        'å¼ƒæƒ', 'æ£„æ¬Š', 'æ˜¯ï¼Œ', 'å¦ï¼Œ',
        # æ—¶é—´æ ‡ç­¾ï¼ˆéæŒ‡æ ‡ï¼‰
        'å¼€æ³¨æ—¶é—´', 'é–‹æ³¨æ™‚é–“', 'å‘é‚€æ—¶é—´', 'ç™¼é‚€æ™‚é–“',
        # å…¬å‘Šä¿¡æ¯
        'æ‹›è˜', 'è§£å°', 'ç”³è¯‰', 'ç”³è¨´', 'QQç¾¤', 'TGç¾¤', 'PMç®¡ç†',
    )

    # è€ƒæ ¸åŒºå—ç»“æŸæ ‡è®°
    _ASSESSMENT_END_MARKERS: Tuple[str, ...] = (
        'æœ€æ–°ç§å­', 'æœ€æ–°ç™¼å¸ƒ', 'æœ€æ–°å¸–å­', 'è®ºå›', 'è«–å£‡', 'å…¬å‘Š', 'å…¬å‘Šæ ',
        'çƒ­é—¨', 'ç†±é–€', 'æ¨è', 'æ¨è–¦', 'æ’è¡Œ', 'æ¦œå•', 'æ¦œå–®',
        'å‹æƒ…é“¾æ¥', 'å‹æƒ…é€£çµ', 'ç«™ç‚¹ç»Ÿè®¡', 'ç«™é»çµ±è¨ˆ',
        'ç‰ˆæƒ', 'ç‰ˆæ¬Š', 'Copyright', 'Â©',
    )

    # æ”¯æŒçš„æ—¥æœŸæ—¶é—´æ ¼å¼
    _DATETIME_FORMATS: Tuple[str, ...] = (
        '%Y-%m-%d %H:%M:%S',
        '%Y-%m-%d %H:%M',
        '%Y/%m/%d %H:%M:%S',
        '%Y/%m/%d %H:%M',
        '%Y-%m-%d',
        '%Y/%m/%d',
    )

    # çŠ¶æ€å…³é”®è¯æ˜ å°„ï¼ˆç®€ç¹ä½“ï¼‰- æ³¨æ„ï¼šå¦å®šè¯å¿…é¡»åœ¨è‚¯å®šè¯ä¹‹å‰æ£€æŸ¥
    _STATUS_KEYWORDS: Dict[str, bool] = {
        # å¦å®šè¯ï¼ˆå¿…é¡»å…ˆæ£€æŸ¥ï¼‰
        'æœªé€šè¿‡': False, 'æœªé€šé': False, 'ä¸åˆæ ¼': False,
        'å¤±æ•—': False, 'å¤±è´¥': False, 'æœªé”æ¨™': False, 'æœªè¾¾æ ‡': False,
        'æœªå®Œæˆ': False, 'æœªé”æˆ': False, 'æœªè¾¾æˆ': False,
        'fail': False, 'failed': False, 'incomplete': False,
        # è‚¯å®šè¯
        'å·²é€šè¿‡': True, 'å·²é€šé': True, 'å·²å®Œæˆ': True,
        'å·²é”æ¨™': True, 'å·²è¾¾æ ‡': True, 'å·²é”æˆ': True, 'å·²è¾¾æˆ': True,
        'é€šè¿‡': True, 'é€šé': True, 'åˆæ ¼': True,
        'é”æ¨™': True, 'è¾¾æ ‡': True, 'é”æˆ': True, 'è¾¾æˆ': True,
        'å®Œæˆ': True, 'pass': True, 'passed': True, 'complete': True,
    }

    # é€šè¿‡/æœªé€šè¿‡å›¾æ ‡æ˜ å°„
    _STATUS_ICONS: Dict[str, bool] = {
        # é€šè¿‡å›¾æ ‡
        'âœ“': True, 'âœ”': True, 'âˆš': True, 'â˜‘': True, 'âœ…': True,
        'â­•': True, 'ğŸŸ¢': True, 'ğŸŸ©': True,
        # æœªé€šè¿‡å›¾æ ‡
        'âœ—': False, 'âœ˜': False, 'Ã—': False, 'â˜’': False, 'âŒ': False,
        'â­™': False, 'ğŸ”´': False, 'ğŸŸ¥': False,
    }

    def init_plugin(self, config: dict = None):
        """åˆå§‹åŒ–æ’ä»¶"""
        self.stop_service()

        if config:
            self._enabled = config.get("enabled", False)
            self._onlyonce = config.get("onlyonce", False)
            self._cron = config.get("cron", "")
            self._notify = config.get("notify", False)
            self._notify_days = config.get("notify_days", 3)
            self._selected_sites = config.get("selected_sites", [])

        # ä»æ•°æ®åº“åŠ è½½ç¼“å­˜æ•°æ®
        self._cached_statuses = self.get_data('cached_statuses') or []

        if self._onlyonce:
            self._scheduler = BackgroundScheduler(timezone=settings.TZ)
            self._scheduler.add_job(
                func=self.__refresh_assessment,
                trigger="date",
                run_date=datetime.now(tz=pytz.timezone(settings.TZ)) + timedelta(seconds=3),
                name="ç«™ç‚¹è€ƒæ ¸çŠ¶æ€åˆ·æ–°"
            )
            self._scheduler.start()
            # å…³é—­ä¸€æ¬¡æ€§å¼€å…³
            self._onlyonce = False
            self.__update_config()

    def get_state(self) -> bool:
        """è·å–æ’ä»¶çŠ¶æ€"""
        return self._enabled

    def __update_config(self):
        """æ›´æ–°é…ç½®"""
        self.update_config({
            "enabled": self._enabled,
            "onlyonce": self._onlyonce,
            "cron": self._cron,
            "notify": self._notify,
            "notify_days": self._notify_days,
            "selected_sites": self._selected_sites,
        })

    @staticmethod
    def get_command() -> List[Dict[str, Any]]:
        """å®šä¹‰è¿œç¨‹æ§åˆ¶å‘½ä»¤"""
        return [{
            "cmd": "/site_assessment",
            "event": EventType.PluginAction,
            "desc": "åˆ·æ–°ç«™ç‚¹è€ƒæ ¸çŠ¶æ€",
            "category": "ç«™ç‚¹",
            "data": {"action": "site_assessment"}
        }]

    def get_api(self) -> List[Dict[str, Any]]:
        """è·å–æ’ä»¶API"""
        return [{
            "path": "/assessment_status",
            "endpoint": self.get_assessment_status,
            "methods": ["GET"],
            "summary": "è·å–ç«™ç‚¹è€ƒæ ¸çŠ¶æ€",
            "description": "è·å–æ‰€æœ‰é…ç½®ç«™ç‚¹çš„è€ƒæ ¸çŠ¶æ€",
        }]

    def get_service(self) -> List[Dict[str, Any]]:
        """æ³¨å†Œæ’ä»¶å…¬å…±æœåŠ¡"""
        if self._enabled and self._cron:
            try:
                return [{
                    "id": "SiteAssessment",
                    "name": "ç«™ç‚¹è€ƒæ ¸çŠ¶æ€åˆ·æ–°",
                    "trigger": CronTrigger.from_crontab(self._cron),
                    "func": self.__refresh_assessment,
                    "kwargs": {}
                }]
            except Exception as e:
                logger.error(f"ç«™ç‚¹è€ƒæ ¸çŠ¶æ€æœåŠ¡é…ç½®é”™è¯¯: {e}")
        return []

    def stop_service(self):
        """åœæ­¢æœåŠ¡"""
        try:
            if self._scheduler:
                self._scheduler.remove_all_jobs()
                if self._scheduler.running:
                    self._scheduler.shutdown()
                self._scheduler = None
        except Exception as e:
            logger.error(f"åœæ­¢ç«™ç‚¹è€ƒæ ¸çŠ¶æ€æœåŠ¡å¤±è´¥: {e}")

    def get_form(self) -> Tuple[List[dict], Dict[str, Any]]:
        """æ‹¼è£…æ’ä»¶é…ç½®é¡µé¢"""
        # è·å–ç«™ç‚¹åˆ—è¡¨
        site_options = [
            {"title": site.name, "value": site.id}
            for site in SiteOper().list_order_by_pri()
        ]
        return [
            {
                'component': 'VForm',
                'content': [
                    {
                        'component': 'VRow',
                        'content': [
                            {
                                'component': 'VCol',
                                'props': {'cols': 12, 'md': 3},
                                'content': [{
                                    'component': 'VSwitch',
                                    'props': {'model': 'enabled', 'label': 'å¯ç”¨æ’ä»¶'}
                                }]
                            },
                            {
                                'component': 'VCol',
                                'props': {'cols': 12, 'md': 3},
                                'content': [{
                                    'component': 'VSwitch',
                                    'props': {'model': 'notify', 'label': 'å‘é€é€šçŸ¥'}
                                }]
                            },
                            {
                                'component': 'VCol',
                                'props': {'cols': 12, 'md': 3},
                                'content': [{
                                    'component': 'VSwitch',
                                    'props': {'model': 'onlyonce', 'label': 'ç«‹å³è¿è¡Œä¸€æ¬¡'}
                                }]
                            }
                        ]
                    },
                    {
                        'component': 'VRow',
                        'content': [
                            {
                                'component': 'VCol',
                                'props': {'cols': 12, 'md': 4},
                                'content': [{
                                    'component': 'VCronField',
                                    'props': {
                                        'model': 'cron',
                                        'label': 'æ‰§è¡Œå‘¨æœŸ',
                                        'placeholder': '5ä½cronè¡¨è¾¾å¼'
                                    }
                                }]
                            },
                            {
                                'component': 'VCol',
                                'props': {'cols': 12, 'md': 4},
                                'content': [{
                                    'component': 'VTextField',
                                    'props': {
                                        'model': 'notify_days',
                                        'label': 'æå‰é€šçŸ¥å¤©æ•°',
                                        'type': 'number'
                                    }
                                }]
                            },
                            {
                                'component': 'VCol',
                                'props': {'cols': 12, 'md': 4},
                                'content': [{
                                    'component': 'VSelect',
                                    'props': {
                                        'model': 'selected_sites',
                                        'label': 'é€‰æ‹©è€ƒæ ¸ç«™ç‚¹',
                                        'items': site_options,
                                        'multiple': True,
                                        'chips': True,
                                        'clearable': True
                                    }
                                }]
                            }
                        ]
                    },
                    {
                        'component': 'VRow',
                        'content': [{
                            'component': 'VCol',
                            'props': {'cols': 12},
                            'content': [{
                                'component': 'VAlert',
                                'props': {
                                    'type': 'info',
                                    'variant': 'tonal',
                                    'text': 'ä½¿ç”¨è¯´æ˜ï¼šé€‰æ‹©éœ€è¦ç›‘æ§çš„ç«™ç‚¹ï¼ˆç•™ç©ºåˆ™æ£€æŸ¥å…¨éƒ¨ç«™ç‚¹ï¼‰ï¼Œæ’ä»¶ä¼šè‡ªåŠ¨æŠ“å–ç«™ç‚¹é¦–é¡µçš„è€ƒæ ¸ä¿¡æ¯'
                                }
                            }]
                        }]
                    }
                ]
            }
        ], {
            "enabled": False,
            "onlyonce": False,
            "cron": "0 8 * * *",
            "notify": True,
            "notify_days": 3,
            "selected_sites": [],
        }

    def get_page(self) -> List[dict]:
        """æ’ä»¶è¯¦æƒ…é¡µé¢ - æ˜¾ç¤ºè€ƒæ ¸çŠ¶æ€ï¼ˆè¯»å–ç¼“å­˜æ•°æ®ï¼‰"""
        statuses = self._cached_statuses
        if not statuses:
            return [{
                'component': 'div',
                'text': 'æš‚æ— æ•°æ®ï¼Œè¯·å…ˆå¯ç”¨æ’ä»¶å¹¶è¿è¡Œä¸€æ¬¡åˆ·æ–°',
                'props': {'class': 'text-center pa-4'}
            }]

        # æ„å»ºè¡¨æ ¼è¡Œ
        table_rows = []
        for status in statuses:
            color = self.__get_status_color(status['status'])
            status_text = {'completed': 'å·²é€šè¿‡', 'in_progress': 'è€ƒæ ¸ä¸­',
                          'failed': 'æœªé€šè¿‡', 'unknown': 'æœªçŸ¥'}.get(status['status'], 'æœªçŸ¥')

            table_rows.append({
                'component': 'tr',
                'props': {'class': 'text-sm'},
                'content': [
                    {'component': 'td', 'props': {'class': 'whitespace-nowrap'},
                     'text': status['site_name']},
                    {'component': 'td', 'props': {'class': f'text-{color}'},
                     'text': status_text},
                    {'component': 'td', 'text': f"{status['progress']*100:.0f}%"},
                    {'component': 'td',
                     'text': f"{status['remaining_days']}å¤©" if status.get('remaining_days') is not None else '-'},
                    {'component': 'td', 'props': {'class': 'text-caption'},
                     'text': status.get('message', '')}
                ]
            })

        return [{
            'component': 'VTable',
            'props': {'hover': True},
            'content': [
                {
                    'component': 'thead',
                    'content': [
                        {'component': 'th', 'text': 'ç«™ç‚¹'},
                        {'component': 'th', 'text': 'çŠ¶æ€'},
                        {'component': 'th', 'text': 'è¿›åº¦'},
                        {'component': 'th', 'text': 'å‰©ä½™'},
                        {'component': 'th', 'text': 'è¯¦æƒ…'}
                    ]
                },
                {
                    'component': 'tbody',
                    'content': table_rows
                }
            ]
        }]

    def get_dashboard(self, key: str = None, **kwargs) -> Optional[Tuple[Dict[str, Any], Dict[str, Any], List[dict]]]:
        """è·å–ä»ªè¡¨æ¿ç»„ä»¶ï¼ˆè¯»å–ç¼“å­˜æ•°æ®ï¼‰"""
        statuses = self._cached_statuses
        if not statuses:
            return None

        elements = []
        for status in statuses:
            color = self.__get_status_color(status['status'])
            elements.append(self.__build_status_card(status, color))

        return (
            {"cols": 12, "md": 12},
            {"refresh": 3600},
            [{'component': 'VRow', 'content': elements}]
        )

    def __build_status_card(self, status: Dict, color: str) -> Dict:
        """æ„å»ºå•ä¸ªçŠ¶æ€å¡ç‰‡"""
        return {
            'component': 'VCol',
            'props': {'cols': 12, 'md': 6, 'lg': 4},
            'content': [{
                'component': 'VCard',
                'props': {'variant': 'outlined', 'class': 'mb-2'},
                'content': [
                    {
                        'component': 'VCardTitle',
                        'props': {'class': f'text-{color}'},
                        'text': status['site_name']
                    },
                    {
                        'component': 'VCardText',
                        'content': [
                            {
                                'component': 'VProgressLinear',
                                'props': {
                                    'model-value': status['progress'] * 100,
                                    'color': color,
                                    'height': 20,
                                    'rounded': True
                                }
                            },
                            {
                                'component': 'div',
                                'props': {'class': 'mt-2'},
                                'text': f"è¿›åº¦: {status['progress']*100:.1f}%"
                            },
                            {
                                'component': 'div',
                                'text': f"å‰©ä½™: {status['remaining_days']}å¤©" if status.get('remaining_days') else "æ— æœŸé™"
                            },
                            {
                                'component': 'div',
                                'props': {'class': 'text-caption'},
                                'text': status.get('message', '')
                            }
                        ]
                    }
                ]
            }]
        }

    @staticmethod
    def __get_status_color(status: str) -> str:
        """æ ¹æ®çŠ¶æ€è¿”å›é¢œè‰²"""
        color_map = {
            'completed': 'success',
            'in_progress': 'warning',
            'failed': 'error',
            'info': 'primary',
            'unknown': 'grey'
        }
        return color_map.get(status, 'grey')

    def get_assessment_status(self) -> List[Dict[str, Any]]:
        """API: è·å–è€ƒæ ¸çŠ¶æ€ï¼ˆè¯»å–ç¼“å­˜æ•°æ®ï¼‰"""
        return self._cached_statuses

    def __refresh_assessment(self):
        """åˆ·æ–°è€ƒæ ¸çŠ¶æ€å¹¶å‘é€é€šçŸ¥"""
        logger.info("å¼€å§‹åˆ·æ–°ç«™ç‚¹è€ƒæ ¸çŠ¶æ€...")
        statuses = self.__calculate_all_status()

        # æ›´æ–°å†…å­˜ç¼“å­˜
        self._cached_statuses = statuses

        # æŒä¹…åŒ–åˆ°æ•°æ®åº“
        self.save_data('cached_statuses', statuses)

        if self._notify and statuses:
            for status in statuses:
                self.__check_and_notify(status)

        logger.info(f"ç«™ç‚¹è€ƒæ ¸çŠ¶æ€åˆ·æ–°å®Œæˆï¼Œå…±{len(statuses)}ä¸ªç«™ç‚¹")

    def __check_and_notify(self, status: Dict[str, Any]):
        """æ£€æŸ¥å¹¶å‘é€é€šçŸ¥"""
        remaining = status.get('remaining_days')
        if remaining is None:
            return

        if status['status'] == 'in_progress' and remaining <= self._notify_days:
            self.post_message(
                mtype=NotificationType.SiteMessage,
                title=f"ã€ç«™ç‚¹è€ƒæ ¸æé†’ã€‘{status['site_name']}",
                text=f"è€ƒæ ¸å‰©ä½™ {remaining} å¤©\n"
                     f"å½“å‰è¿›åº¦: {status['progress']*100:.1f}%\n"
                     f"{status.get('message', '')}"
            )
        elif status['status'] == 'failed':
            self.post_message(
                mtype=NotificationType.SiteMessage,
                title=f"ã€ç«™ç‚¹è€ƒæ ¸å¤±è´¥ã€‘{status['site_name']}",
                text=f"è€ƒæ ¸å·²è¶…æœŸï¼\n{status.get('message', '')}"
            )

    def __calculate_all_status(self) -> List[Dict[str, Any]]:
        """è®¡ç®—æ‰€æœ‰ç«™ç‚¹çš„è€ƒæ ¸çŠ¶æ€ï¼Œåªè¿”å›æ£€æµ‹åˆ°è€ƒæ ¸çš„ç«™ç‚¹"""
        statuses = []

        # è·å–æ‰€æœ‰ç«™ç‚¹ä¿¡æ¯
        all_sites = {site.id: site for site in SiteOper().list_order_by_pri()}

        # ç¡®å®šç›®æ ‡ç«™ç‚¹ï¼ˆç•™ç©ºåˆ™æ£€æŸ¥å…¨éƒ¨ç«™ç‚¹ï¼‰
        if self._selected_sites:
            # ç¡®ä¿ç±»å‹ä¸€è‡´ï¼ˆè½¬ä¸ºæ•´æ•°ï¼‰
            target_sites = [int(sid) for sid in self._selected_sites if sid]
            logger.info(f"å·²é€‰æ‹© {len(target_sites)} ä¸ªç«™ç‚¹è¿›è¡Œè€ƒæ ¸æ£€æŸ¥")
        else:
            target_sites = list(all_sites.keys())
            logger.info(f"æœªé€‰æ‹©ç«™ç‚¹ï¼Œæ£€æŸ¥å…¨éƒ¨ {len(target_sites)} ä¸ªç«™ç‚¹")

        for site_id in target_sites:
            site = all_sites.get(site_id)
            if not site:
                continue
            try:
                status = self.__calculate_site_status(site)
                # åªæ·»åŠ æ£€æµ‹åˆ°è€ƒæ ¸çš„ç«™ç‚¹
                if status:
                    statuses.append(status)
            except Exception as e:
                logger.error(f"è®¡ç®—ç«™ç‚¹ {site.name} è€ƒæ ¸çŠ¶æ€å¤±è´¥: {e}")

        return statuses

    def __calculate_site_status(self, site) -> Optional[Dict[str, Any]]:
        """è®¡ç®—ç«™ç‚¹è€ƒæ ¸çŠ¶æ€ï¼ˆé€šè¿‡æŠ“å–ç«™ç‚¹é¦–é¡µè·å–è€ƒæ ¸ä¿¡æ¯ï¼‰"""
        site_id = site.id
        site_name = site.name

        # æŠ“å–ç«™ç‚¹é¦–é¡µè€ƒæ ¸ä¿¡æ¯
        return self.__build_info_status(site_id, site_name)

    def __build_info_status(self, site_id: int, site_name: str) -> Optional[Dict[str, Any]]:
        """é€šè¿‡è®¿é—®ç«™ç‚¹é¦–é¡µæŠ“å–è€ƒæ ¸ä¿¡æ¯ï¼Œæœªæ£€æµ‹åˆ°è€ƒæ ¸è¿”å›None"""
        # è·å–ç«™ç‚¹ä¿¡æ¯
        site = SiteOper().get(site_id)
        if not site:
            return None

        # æŠ“å–ç«™ç‚¹é¦–é¡µè€ƒæ ¸ä¿¡æ¯
        assessment = self.__fetch_site_assessment(site)

        if assessment:
            return self.__build_assessment_result(site_id, site_name, assessment)
        else:
            return None

    def __fetch_site_assessment(self, site) -> Optional[Dict[str, Any]]:
        """è®¿é—®ç«™ç‚¹é¦–é¡µæŠ“å–è€ƒæ ¸ä¿¡æ¯"""
        try:
            # ç¬¬ä¸€æ¬¡å°è¯•ï¼šæŒ‰ç«™ç‚¹é…ç½®è®¿é—®
            res = RequestUtils(
                cookies=site.cookie,
                ua=site.ua or settings.USER_AGENT,
                proxies=settings.PROXY if site.proxy else None,
                timeout=site.timeout or 15
            ).get_res(url=site.url)

            # è®¿é—®å¤±è´¥ä¸”æœªä½¿ç”¨ä»£ç†ï¼Œå°è¯•ä½¿ç”¨ä»£ç†é‡è¯•
            if (not res or res.status_code != 200) and not site.proxy:
                logger.info(f"ç«™ç‚¹ {site.name} ç›´è¿å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ä»£ç†è®¿é—®...")
                res = RequestUtils(
                    cookies=site.cookie,
                    ua=site.ua or settings.USER_AGENT,
                    proxies=settings.PROXY,
                    timeout=site.timeout or 15
                ).get_res(url=site.url)

            if not res or res.status_code != 200:
                logger.warning(f"è®¿é—®ç«™ç‚¹ {site.name} å¤±è´¥")
                return None

            return self.__parse_assessment_html(res.text)
        except Exception as e:
            logger.error(f"æŠ“å–ç«™ç‚¹ {site.name} è€ƒæ ¸ä¿¡æ¯å¤±è´¥: {e}")
            return None

    def __normalize_html(self, html: str) -> Tuple[str, List[str]]:
        """
        å°†HTMLæ ‡å‡†åŒ–ä¸ºæ¢è¡Œåˆ†éš”çš„çº¯æ–‡æœ¬
        è¿”å›: (æ ‡å‡†åŒ–æ–‡æœ¬, è¡Œåˆ—è¡¨)
        """
        text = unescape(html)
        # ç§»é™¤scriptã€styleã€noscriptç­‰æ ‡ç­¾åŠå…¶å†…å®¹
        text = re.sub(r'(?is)<script[^>]*>.*?</script>', '', text)
        text = re.sub(r'(?is)<style[^>]*>.*?</style>', '', text)
        text = re.sub(r'(?is)<noscript[^>]*>.*?</noscript>', '', text)
        # å°†å„ç§æ¢è¡Œæ ‡ç­¾è½¬ä¸ºæ¢è¡Œç¬¦
        text = re.sub(r'(?i)<br\s*/?>', '\n', text)
        text = re.sub(r'(?i)</?(?:p|div|li|tr|td|h\d)[^>]*>', '\n', text)
        # ç§»é™¤æ‰€æœ‰HTMLæ ‡ç­¾
        text = re.sub(r'<[^>]+>', '', text)
        # æ ‡å‡†åŒ–ç©ºç™½å­—ç¬¦
        text = text.replace('\xa0', ' ')
        # æŒ‰è¡Œåˆ†å‰²å¹¶æ¸…ç†
        lines = []
        for line in text.splitlines():
            cleaned = re.sub(r'[ \t\u3000]+', ' ', line).strip()
            if cleaned:
                lines.append(cleaned)
        return '\n'.join(lines), lines

    def __extract_tables_from_html(self, html: str) -> List[List[List[str]]]:
        """
        ä»HTMLä¸­æå–è¡¨æ ¼æ•°æ®
        è¿”å›: è¡¨æ ¼åˆ—è¡¨ï¼Œæ¯ä¸ªè¡¨æ ¼æ˜¯è¡Œåˆ—è¡¨ï¼Œæ¯è¡Œæ˜¯å•å…ƒæ ¼åˆ—è¡¨
        """
        tables = []
        try:
            # ä½¿ç”¨ lxml è§£æ HTML
            tree = etree.HTML(html)
            if tree is None:
                return tables

            # æŸ¥æ‰¾æ‰€æœ‰è¡¨æ ¼
            for table in tree.xpath('//table'):
                table_data = []
                # ä¼˜å…ˆæŸ¥æ‰¾ tbodyï¼Œå¦‚æœæ²¡æœ‰åˆ™ç›´æ¥æŸ¥æ‰¾ tr
                rows = table.xpath('.//tbody/tr') or table.xpath('.//tr')
                for row in rows:
                    row_data = []
                    # è·å–æ‰€æœ‰å•å…ƒæ ¼ï¼ˆth å’Œ tdï¼‰
                    cells = row.xpath('.//th | .//td')
                    for cell in cells:
                        # è·å–å•å…ƒæ ¼æ–‡æœ¬ï¼ŒåŒ…æ‹¬åµŒå¥—å…ƒç´ 
                        text = ''.join(cell.itertext()).strip()
                        # æ ‡å‡†åŒ–ç©ºç™½
                        text = re.sub(r'\s+', ' ', text)
                        row_data.append(text)
                    if row_data:
                        table_data.append(row_data)
                if table_data:
                    tables.append(table_data)
        except Exception as e:
            logger.debug(f"è¡¨æ ¼è§£æå¤±è´¥: {e}")

        return tables

    def __extract_metrics_from_tables(self, tables: List[List[List[str]]]) -> List[Dict[str, Any]]:
        """
        ä»è¡¨æ ¼æ•°æ®ä¸­æå–è€ƒæ ¸æŒ‡æ ‡
        æ”¯æŒå¤šç§è¡¨æ ¼å¸ƒå±€ï¼š
        - æ¨ªå‘å¸ƒå±€ï¼šæŒ‡æ ‡å | è¦æ±‚ | å½“å‰ | ç»“æœ
        - çºµå‘å¸ƒå±€ï¼šæŒ‡æ ‡å | å€¼
        - æ··åˆå¸ƒå±€ï¼šæŒ‡æ ‡å | å½“å‰å€¼/è¦æ±‚å€¼
        """
        metrics = []

        for table in tables:
            if len(table) < 2:
                continue

            # æ£€æŸ¥æ˜¯å¦æ˜¯è€ƒæ ¸ç›¸å…³è¡¨æ ¼
            table_text = ' '.join(' '.join(row) for row in table)
            if not self.__is_assessment_table(table_text):
                continue

            # å°è¯•è§£æè¡¨æ ¼ç»“æ„
            header = table[0] if table else []
            header_lower = [h.lower() for h in header]

            # æ£€æµ‹è¡¨æ ¼ç±»å‹
            if self.__is_horizontal_layout(header_lower):
                # æ¨ªå‘å¸ƒå±€ï¼šæ¯è¡Œä¸€ä¸ªæŒ‡æ ‡
                metrics.extend(self.__parse_horizontal_table(table))
            elif self.__is_vertical_layout(header_lower, table):
                # çºµå‘å¸ƒå±€ï¼šæ¯åˆ—ä¸€ä¸ªæŒ‡æ ‡
                metrics.extend(self.__parse_vertical_table(table))
            else:
                # å°è¯•é€šç”¨è§£æ
                metrics.extend(self.__parse_generic_table(table))

        return metrics

    def __is_assessment_table(self, table_text: str) -> bool:
        """æ£€æŸ¥è¡¨æ ¼æ˜¯å¦åŒ…å«è€ƒæ ¸ç›¸å…³å†…å®¹"""
        text_lower = table_text.lower()
        # æ£€æŸ¥æ˜¯å¦åŒ…å«è€ƒæ ¸å…³é”®è¯
        for keyword in self._ASSESSMENT_KEYWORDS:
            if keyword.lower() in text_lower:
                return True
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æŒ‡æ ‡å…³é”®è¯
        for keywords in self._METRIC_KEYWORDS.values():
            for kw in keywords:
                if kw.lower() in text_lower:
                    return True
        return False

    def __is_horizontal_layout(self, header: List[str]) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ˜¯æ¨ªå‘å¸ƒå±€è¡¨æ ¼ï¼ˆæŒ‡æ ‡å | è¦æ±‚ | å½“å‰ | ç»“æœï¼‰"""
        keywords = {
            'name': ('æŒ‡æ ‡', 'é …ç›®', 'é¡¹ç›®', 'name', 'åç§°', 'åç¨±'),
            'required': ('è¦æ±‚', 'ç›®æ ‡', 'ç›®æ¨™', 'required', 'target', 'æ ‡å‡†', 'æ¨™æº–'),
            'current': ('å½“å‰', 'ç•¶å‰', 'ç›®å‰', 'current', 'å·²å®Œæˆ', 'å·²é”æˆ'),
            'result': ('ç»“æœ', 'çµæœ', 'çŠ¶æ€', 'ç‹€æ…‹', 'result', 'status', 'æ˜¯å¦é€šè¿‡', 'æ˜¯å¦é€šé'),
        }
        found = set()
        for h in header:
            h_lower = h.lower()
            for key, kws in keywords.items():
                if any(kw.lower() in h_lower for kw in kws):
                    found.add(key)
        return len(found) >= 2

    def __is_vertical_layout(self, header: List[str], table: List[List[str]]) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ˜¯çºµå‘å¸ƒå±€è¡¨æ ¼"""
        # çºµå‘å¸ƒå±€é€šå¸¸åªæœ‰2åˆ—ï¼Œç¬¬ä¸€åˆ—æ˜¯æŒ‡æ ‡å
        if not table:
            return False
        # å¤§éƒ¨åˆ†è¡Œæ˜¯2åˆ—
        two_col_count = sum(1 for row in table if len(row) == 2)
        return two_col_count >= len(table) * 0.7

    def __parse_horizontal_table(self, table: List[List[str]]) -> List[Dict[str, Any]]:
        """è§£ææ¨ªå‘å¸ƒå±€è¡¨æ ¼"""
        metrics = []
        if len(table) < 2:
            return metrics

        header = table[0]
        # ç¡®å®šåˆ—ç´¢å¼•
        col_map = self.__detect_column_mapping(header)

        for row in table[1:]:
            if len(row) < 2:
                continue

            metric = self.__create_metric_from_row(row, col_map, header)
            if metric and metric.get('name'):
                metrics.append(metric)

        return metrics

    def __detect_column_mapping(self, header: List[str]) -> Dict[str, int]:
        """æ£€æµ‹è¡¨æ ¼åˆ—æ˜ å°„"""
        col_map = {}
        keywords = {
            'name': ('æŒ‡æ ‡', 'é …ç›®', 'é¡¹ç›®', 'name', 'åç§°', 'åç¨±', 'è€ƒæ ¸é¡¹', 'è€ƒæ ¸é …'),
            'required': ('è¦æ±‚', 'ç›®æ ‡', 'ç›®æ¨™', 'required', 'target', 'æ ‡å‡†', 'æ¨™æº–', 'éœ€è¦', 'éœ€é”'),
            'current': ('å½“å‰', 'ç•¶å‰', 'ç›®å‰', 'current', 'å·²å®Œæˆ', 'å·²é”æˆ', 'å®Œæˆ', 'è¾¾æˆ', 'é”æˆ'),
            'result': ('ç»“æœ', 'çµæœ', 'çŠ¶æ€', 'ç‹€æ…‹', 'result', 'status', 'é€šè¿‡', 'é€šé'),
        }

        for idx, h in enumerate(header):
            h_lower = h.lower()
            for key, kws in keywords.items():
                if key not in col_map and any(kw.lower() in h_lower for kw in kws):
                    col_map[key] = idx
                    break

        # å¦‚æœæ²¡æ‰¾åˆ° name åˆ—ï¼Œé»˜è®¤ç¬¬ä¸€åˆ—
        if 'name' not in col_map:
            col_map['name'] = 0

        return col_map

    def __create_metric_from_row(self, row: List[str], col_map: Dict[str, int],
                                  header: List[str]) -> Optional[Dict[str, Any]]:
        """ä»è¡¨æ ¼è¡Œåˆ›å»ºæŒ‡æ ‡"""
        metric = {
            'name': None,
            'index': None,
            'required': None,
            'current': None,
            'passed': None,
        }

        # æå–å„å­—æ®µ
        for key, idx in col_map.items():
            if idx < len(row):
                value = row[idx].strip()
                if key == 'name':
                    metric['name'] = value
                elif key == 'required':
                    metric['required'] = value
                elif key == 'current':
                    metric['current'] = value
                elif key == 'result':
                    metric['passed'] = self.__interpret_status(value)

        # å¦‚æœ required/current æœªä»æŒ‡å®šåˆ—è·å–ï¼Œå°è¯•ä»å‰©ä½™åˆ—è§£æ
        if not metric['required'] or not metric['current']:
            for idx, cell in enumerate(row):
                if idx in col_map.values():
                    continue
                # å°è¯•è§£æä¸º "å½“å‰/è¦æ±‚" æ ¼å¼
                ratio = self.__parse_ratio_value(cell)
                if ratio:
                    metric['current'] = ratio['current']
                    metric['required'] = ratio['required']
                    if metric['passed'] is None:
                        metric['passed'] = ratio.get('passed')
                    break

        # å°è¯•ä» current æ¨æ–­ passed
        if metric['passed'] is None and metric['current']:
            metric['passed'] = self.__interpret_status(metric['current'])

        # å¦‚æœæœ‰ current å’Œ requiredï¼Œè®¡ç®— passed
        if metric['passed'] is None and metric['current'] and metric['required']:
            cur_val = self.__parse_metric_value(metric['current'])
            req_val = self.__parse_metric_value(metric['required'])
            if cur_val is not None and req_val is not None and req_val > 0:
                metric['passed'] = cur_val >= req_val

        return metric if metric.get('name') else None

    def __parse_vertical_table(self, table: List[List[str]]) -> List[Dict[str, Any]]:
        """è§£æçºµå‘å¸ƒå±€è¡¨æ ¼"""
        metrics = []

        for row in table:
            if len(row) < 2:
                continue

            name = row[0].strip()
            value = row[1].strip()

            # æ£€æŸ¥æ˜¯å¦æ˜¯æŒ‡æ ‡åç§°
            if not self.__is_metric_name(name):
                continue

            metric = {
                'name': name,
                'index': None,
                'required': None,
                'current': None,
                'passed': None,
            }

            # å°è¯•è§£æå€¼
            ratio = self.__parse_ratio_value(value)
            if ratio:
                metric.update(ratio)
            else:
                metric['current'] = value
                metric['passed'] = self.__interpret_status(value)

            metrics.append(metric)

        return metrics

    def __parse_generic_table(self, table: List[List[str]]) -> List[Dict[str, Any]]:
        """é€šç”¨è¡¨æ ¼è§£æ"""
        metrics = []

        for row in table:
            # å°è¯•ä»è¡Œä¸­æå–æŒ‡æ ‡
            row_text = ' '.join(row)

            # è·³è¿‡éæŒ‡æ ‡è¡Œ
            if not self.__contains_metric_keywords(row_text):
                continue

            metric = self.__parse_simple_metric_from_text(row_text)
            if metric:
                metrics.append(metric)

        return metrics

    def __is_metric_name(self, name: str, strict: bool = True) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„æŒ‡æ ‡åç§°
        strict=True æ—¶ä½¿ç”¨ç™½åå•ç²¾ç¡®åŒ¹é…ï¼Œstrict=False æ—¶ä½¿ç”¨å…³é”®è¯åŒ¹é…
        """
        if not name:
            return False

        # åç§°é•¿åº¦é™åˆ¶ï¼ˆè€ƒæ ¸æŒ‡æ ‡åç§°é€šå¸¸å¾ˆçŸ­ï¼‰
        if len(name) > 10:
            return False

        # é»‘åå•æ£€æŸ¥ï¼šåŒ…å«æ— æ•ˆæ¨¡å¼åˆ™æ’é™¤
        for pattern in self._INVALID_METRIC_PATTERNS:
            if pattern.lower() in name.lower():
                return False

        # ä¸¥æ ¼æ¨¡å¼ï¼šä½¿ç”¨ç™½åå•ç²¾ç¡®åŒ¹é…
        if strict:
            # æ£€æŸ¥æ˜¯å¦ç²¾ç¡®åŒ¹é…æœ‰æ•ˆæŒ‡æ ‡åç§°
            for valid_name in self._VALID_METRIC_NAMES:
                if name == valid_name or name.replace(' ', '') == valid_name:
                    return True
            # ä¹Ÿæ£€æŸ¥æ˜¯å¦ä»¥æœ‰æ•ˆåç§°å¼€å¤´æˆ–ç»“å°¾
            for valid_name in self._VALID_METRIC_NAMES:
                if name.startswith(valid_name) or name.endswith(valid_name):
                    return True
            return False

        # å®½æ¾æ¨¡å¼ï¼šå…³é”®è¯åŒ¹é…
        name_lower = name.lower()
        for keywords in self._METRIC_KEYWORDS.values():
            for kw in keywords:
                if kw.lower() in name_lower:
                    return True
        return False

    def __is_valid_metric_value(self, value: str) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„æŒ‡æ ‡å€¼ï¼ˆç”¨äºè¿‡æ»¤æ— å…³å†…å®¹ï¼‰
        æœ‰æ•ˆçš„æŒ‡æ ‡å€¼é€šå¸¸æ˜¯ï¼š
        - "å½“å‰å€¼ / ç›®æ ‡å€¼" æ ¼å¼
        - "å·²é€šè¿‡"ã€"æœªé€šè¿‡" ç­‰çŠ¶æ€æ–‡æœ¬
        - "è¿˜éœ€è¦ X GB" ç­‰æè¿°
        """
        if not value:
            return False

        # å€¼å¤ªé•¿é€šå¸¸ä¸æ˜¯æœ‰æ•ˆçš„æŒ‡æ ‡å€¼
        if len(value) > 100:
            return False

        # åŒ…å«ç§å­æ ‡é¢˜ç‰¹å¾åˆ™æ’é™¤
        title_patterns = [
            r'\d{4}p', r'BluRay', r'Blu-ray', r'WEB-DL', r'REMUX', r'HDR',
            r'H\.26[45]', r'HEVC', r'AVC', r'DTS', r'AAC', r'FLAC', r'Atmos',
            r'å¯¼æ¼”', r'ä¸»æ¼”', r'ç±»åˆ«', r'å­—å¹•', r'å›½è¯­', r'åœ‹èª', r'ä¸­å­—',
            r'ç¬¬\d+å­£', r'å…¨\d+é›†', r'S\d{2}', r'E\d{2}',
            r'\d{4}[-/]\d{2}[-/]\d{2}',  # æ—¥æœŸæ ¼å¼çš„ç§å­
        ]
        for pattern in title_patterns:
            if re.search(pattern, value, re.IGNORECASE):
                return False

        # åŒ…å«ç‰ˆå—/å¸–å­ç‰¹å¾åˆ™æ’é™¤
        if re.search(r'ç‰ˆ[å—å¡Š]|Feedback|Appeal|Record|é—®é¢˜åé¦ˆ|å¤‡æ¡ˆ', value, re.IGNORECASE):
            return False

        # åŒ…å«ç«™ç‚¹ç»Ÿè®¡ç‰¹å¾åˆ™æ’é™¤
        stat_patterns = [
            r'è®¿é—®ç”¨æˆ·', r'è¨ªå•ç”¨æˆ¶', r'æ³¨å†Œç”¨æˆ·', r'è¨»å†Šç”¨æˆ¶',
            r'ä»Šæ—¥', r'æœ¬å‘¨', r'å½“å‰', r'ç¸½',
            r'Peasant|User|Elite|Crazy|Insane|Veteran|Extreme|Ultimate|Master',
        ]
        for pattern in stat_patterns:
            if re.search(pattern, value, re.IGNORECASE):
                return False

        # å¦‚æœå€¼åªæ˜¯ä¸€ä¸ªå¤§æ•°å­—ï¼ˆ>1000ä¸”æ²¡æœ‰å•ä½ï¼‰ï¼Œé€šå¸¸æ˜¯ç«™ç‚¹ç»Ÿè®¡
        pure_number = re.match(r'^[\d,]+$', value.replace(' ', ''))
        if pure_number:
            try:
                num = float(value.replace(',', '').replace(' ', ''))
                if num > 1000:  # è¶…è¿‡1000çš„çº¯æ•°å­—ä¸å¤ªå¯èƒ½æ˜¯è€ƒæ ¸æŒ‡æ ‡
                    return False
            except ValueError:
                pass

        # æœ‰æ•ˆçš„æ ¼å¼ï¼šåŒ…å« "/" æˆ–çŠ¶æ€å…³é”®è¯æˆ– "éœ€" ç­‰
        valid_patterns = [
            r'/',  # å½“å‰/ç›®æ ‡ æ ¼å¼
            r'å·²é€šè¿‡|é€šé|åˆæ ¼|é”æ¨™|è¾¾æ ‡',  # é€šè¿‡çŠ¶æ€
            r'æœªé€šè¿‡|æœªé€šé|ä¸åˆæ ¼|æœªé”æ¨™|æœªè¾¾æ ‡',  # æœªé€šè¿‡çŠ¶æ€
            r'è¿˜éœ€|é‚„éœ€|ä»éœ€|éœ€è¦',  # éœ€è¦æè¿°
            r'^\s*[\d,.]+\s*[A-Za-z]+\s*$',  # å¸¦å•ä½çš„æ•°å€¼ (å¦‚ "100 GB")
        ]

        for pattern in valid_patterns:
            if re.search(pattern, value, re.IGNORECASE):
                return True

        # å¦‚æœæ˜¯ç®€å•çš„æ•°å€¼+å•ä½æ ¼å¼ï¼Œä¹Ÿè®¤ä¸ºæœ‰æ•ˆ
        if re.match(r'^[\d,.]+\s*[A-Za-z%]+$', value.strip()):
            return True

        return False

    def __contains_metric_keywords(self, text: str) -> bool:
        """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«æŒ‡æ ‡å…³é”®è¯"""
        text_lower = text.lower()
        for keywords in self._METRIC_KEYWORDS.values():
            for kw in keywords:
                if kw.lower() in text_lower:
                    return True
        return False

    def __parse_ratio_value(self, value: str) -> Optional[Dict[str, Any]]:
        """
        è§£ææ¯”ä¾‹å€¼æ ¼å¼
        æ”¯æŒ: "100 GB / 500 GB", "100/500", "50%", "å·²é€šè¿‡" ç­‰
        """
        if not value:
            return None

        value = value.strip()

        # æ ¼å¼1: "å½“å‰å€¼ / è¦æ±‚å€¼"
        ratio_match = re.search(
            r'([\d,.]+)\s*([A-Za-z]*)\s*/\s*([\d,.]+)\s*([A-Za-z]*)',
            value
        )
        if ratio_match:
            cur_val = ratio_match.group(1).replace(',', '')
            cur_unit = ratio_match.group(2) or ''
            req_val = ratio_match.group(3).replace(',', '')
            req_unit = ratio_match.group(4) or ''

            current = f"{cur_val} {cur_unit}".strip()
            required = f"{req_val} {req_unit}".strip()

            try:
                passed = float(cur_val) >= float(req_val)
            except ValueError:
                passed = None

            return {'current': current, 'required': required, 'passed': passed}

        # æ ¼å¼2: ç™¾åˆ†æ¯”
        percent_match = re.search(r'([\d.]+)\s*%', value)
        if percent_match:
            percent = float(percent_match.group(1))
            return {
                'current': f"{percent}%",
                'required': '100%',
                'passed': percent >= 100
            }

        # æ ¼å¼3: çŠ¶æ€æ–‡æœ¬
        passed = self.__interpret_status(value)
        if passed is not None:
            return {'current': value, 'required': None, 'passed': passed}

        return None

    def __parse_simple_metric_from_text(self, text: str) -> Optional[Dict[str, Any]]:
        """ä»æ–‡æœ¬è¡Œè§£æç®€å•æŒ‡æ ‡"""
        # å°è¯•åŒ¹é… "æŒ‡æ ‡åï¼šå€¼" æˆ– "æŒ‡æ ‡å å€¼" æ ¼å¼
        patterns = [
            re.compile(r'(?P<name>[\u4e00-\u9fa5]+(?:é‡|ç‡|å€¼|æ•°|æ•¸|é—´|é–“)?)[ï¼š:]\s*(?P<value>.+)', re.IGNORECASE),
            re.compile(r'(?P<name>[\u4e00-\u9fa5]{2,6})\s+(?P<value>[\d,.]+\s*[A-Za-z]*(?:\s*/\s*[\d,.]+\s*[A-Za-z]*)?)', re.IGNORECASE),
        ]

        for pattern in patterns:
            match = pattern.search(text)
            if match and self.__is_metric_name(match.group('name')):
                name = match.group('name').strip()
                value = match.group('value').strip()

                metric = {
                    'name': name,
                    'index': None,
                    'required': None,
                    'current': None,
                    'passed': None,
                }

                ratio = self.__parse_ratio_value(value)
                if ratio:
                    metric.update(ratio)
                else:
                    metric['current'] = value
                    metric['passed'] = self.__interpret_status(value)

                return metric

        return None

    def __extract_time_from_title(self, html: str) -> Optional[str]:
        """ä»HTMLçš„titleå±æ€§ä¸­æå–ç»“æŸæ—¶é—´ï¼ˆåªåœ¨è€ƒæ ¸ç›¸å…³åŒºå—ä¸­æœç´¢ï¼‰"""
        # æ¨¡å¼1ï¼šå…³é”®è¯åœ¨titleä¹‹å‰ï¼ˆæ”¾å®½åˆ°200å­—ç¬¦ï¼‰
        match = re.search(
            r'(?:è€ƒæ ¸|ç»“æŸ|çµæŸ|é‚„æœ‰|è¿˜æœ‰).{0,200}title\s*=\s*["\'](\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})["\']',
            html, re.DOTALL | re.IGNORECASE
        )
        if match:
            logger.debug(f"ä»titleå±æ€§æå–ç»“æŸæ—¶é—´ï¼ˆæ¨¡å¼1ï¼‰: {match.group(1)}")
            return match.group(1)

        # æ¨¡å¼2ï¼štitleåœ¨å…³é”®è¯ä¹‹å‰
        match = re.search(
            r'title\s*=\s*["\'](\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})["\'].{0,200}(?:è€ƒæ ¸|ç»“æŸ|çµæŸ|é‚„æœ‰|è¿˜æœ‰)',
            html, re.DOTALL | re.IGNORECASE
        )
        if match:
            logger.debug(f"ä»titleå±æ€§æå–ç»“æŸæ—¶é—´ï¼ˆæ¨¡å¼2ï¼‰: {match.group(1)}")
            return match.group(1)

        # æ¨¡å¼3ï¼šç›´æ¥æœç´¢titleå±æ€§ä¸­çš„æ—¥æœŸæ—¶é—´ï¼ˆä¸é™åˆ¶å…³é”®è¯ï¼Œæ›´å®½æ¾ï¼‰
        # ç”¨äºæ•è·å¯èƒ½çš„è€ƒæ ¸ç»“æŸæ—¶é—´
        matches = re.findall(
            r'title\s*=\s*["\'](\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})["\']',
            html
        )
        if matches:
            # å¦‚æœæ‰¾åˆ°å¤šä¸ªï¼Œå–ç¬¬ä¸€ä¸ªï¼ˆé€šå¸¸æ˜¯è€ƒæ ¸ç»“æŸæ—¶é—´ï¼‰
            logger.debug(f"ä»titleå±æ€§æå–ç»“æŸæ—¶é—´ï¼ˆæ¨¡å¼3-å®½æ¾ï¼‰: {matches[0]}")
            return matches[0]

        logger.debug("æœªä»titleå±æ€§ä¸­æå–åˆ°ç»“æŸæ—¶é—´")
        return None

    def __parse_assessment_html(self, html: str) -> Optional[Dict[str, Any]]:
        """
        è§£æè€ƒæ ¸HTMLä¿¡æ¯ï¼ˆæ”¯æŒç®€ç¹ä½“ä¸­æ–‡ï¼‰
        ä½¿ç”¨æ–‡æœ¬è§£æç­–ç•¥
        """
        if not html:
            return None

        # åœ¨æ ‡å‡†åŒ–å‰æå–titleå±æ€§ä¸­çš„æ—¶é—´ï¼ˆç”¨äºå€’è®¡æ—¶æ ¼å¼ï¼‰
        title_time = self.__extract_time_from_title(html)

        # æå–ç›¸å¯¹æ—¶é—´ï¼ˆè¿˜æœ‰Xå¤©Xå°æ—¶ï¼‰
        relative_time = self.__extract_relative_time(html)

        # æ ‡å‡†åŒ–HTML
        normalized_text, lines = self.__normalize_html(html)

        # æå–è€ƒæ ¸åç§°å’Œä½ç½®ï¼ˆæ”¯æŒç®€ç¹ä½“ï¼‰
        name, name_index = self.__extract_assessment_name(lines)

        if not name:
            logger.debug("æœªæ‰¾åˆ°è€ƒæ ¸åç§°")
            return None

        assessment = {'name': name, 'metrics': []}
        logger.info(f"æ£€æµ‹åˆ°è€ƒæ ¸: {name}")

        # ç¡®å®šè€ƒæ ¸åŒºå—èŒƒå›´ï¼ˆä»åç§°åˆ°ç»“æŸæ ‡è®°ï¼‰
        end_index = self.__find_assessment_end(lines, name_index)
        lines_in_assessment = lines[name_index:end_index]

        logger.debug(f"è€ƒæ ¸åŒºå—èŒƒå›´: è¡Œ {name_index} ~ {end_index}ï¼ˆå…± {len(lines_in_assessment)} è¡Œï¼‰")

        # æå–æ—¶é—´èŒƒå›´ï¼ˆå¤šç§æ¥æºï¼‰
        start_time, end_time = self.__extract_time_range(lines_in_assessment)
        if start_time and end_time:
            assessment['start_time'] = start_time
            assessment['end_time'] = end_time
            logger.debug(f"è§£ææ—¶é—´: {start_time} ~ {end_time}")
        elif title_time:
            assessment['end_time'] = title_time
            logger.debug(f"ä»titleå±æ€§è§£æç»“æŸæ—¶é—´: {title_time}")
        elif relative_time:
            # ä½¿ç”¨ç›¸å¯¹æ—¶é—´è®¡ç®—ç»“æŸæ—¶é—´
            assessment['end_time'] = relative_time
            logger.debug(f"ä»ç›¸å¯¹æ—¶é—´è§£æç»“æŸæ—¶é—´: {relative_time}")

        # åªä½¿ç”¨æ–‡æœ¬è§£ææå–æŒ‡æ ‡
        text_metrics = self.__extract_metrics(lines_in_assessment)
        assessment['metrics'] = text_metrics

        if text_metrics:
            logger.info(f"å…±è§£æ {len(text_metrics)} ä¸ªè€ƒæ ¸æŒ‡æ ‡")
            return assessment

        logger.debug("æœªæ‰¾åˆ°è€ƒæ ¸æŒ‡æ ‡")
        return None

    def __find_assessment_end(self, lines: List[str], start_index: int) -> int:
        """
        æŸ¥æ‰¾è€ƒæ ¸åŒºå—çš„ç»“æŸä½ç½®
        é€šè¿‡æ£€æµ‹ç»“æŸæ ‡è®°æ¥ç¡®å®šèŒƒå›´
        """
        # æœ€å¤§æœç´¢èŒƒå›´ï¼ˆä»èµ·å§‹ä½ç½®å‘åæœ€å¤š50è¡Œï¼‰
        max_range = min(start_index + 50, len(lines))

        for i in range(start_index + 1, max_range):
            line = lines[i]

            # æ£€æŸ¥æ˜¯å¦é‡åˆ°ç»“æŸæ ‡è®°
            for marker in self._ASSESSMENT_END_MARKERS:
                if marker in line:
                    logger.debug(f"åœ¨è¡Œ {i} æ‰¾åˆ°è€ƒæ ¸åŒºå—ç»“æŸæ ‡è®°: {marker}")
                    return i

            # æ£€æŸ¥æ˜¯å¦é‡åˆ°æ–°çš„è€ƒæ ¸åŒºå—ï¼ˆè¯´æ˜å‰ä¸€ä¸ªç»“æŸäº†ï¼‰
            if 'è€ƒæ ¸' in line and i > start_index + 3:
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°çš„è€ƒæ ¸æ ‡é¢˜
                if re.search(r'[ã€\[ã€Œã€].*è€ƒæ ¸.*[ã€‘\]ã€ã€]', line):
                    return i
                if re.match(r'^(?:æ–°æ‰‹|å…»æˆ|è©¦ç”¨|è¯•ç”¨)', line):
                    return i

        return max_range

    def __extract_relative_time(self, html: str) -> Optional[str]:
        """
        ä»HTMLä¸­æå–ç›¸å¯¹æ—¶é—´å¹¶è½¬æ¢ä¸ºç»å¯¹æ—¶é—´
        æ”¯æŒ: "è¿˜æœ‰3å¤©5å°æ—¶", "å‰©ä½™10å¤©", "è·ç¦»ç»“æŸè¿˜æœ‰2å‘¨"
        """
        # åŒ¹é…ç›¸å¯¹æ—¶é—´æ¨¡å¼
        patterns = [
            # "è¿˜æœ‰Xå¤©Xå°æ—¶Xåˆ†é’Ÿ"
            re.compile(
                r'(?:è¿˜æœ‰|é‚„æœ‰|å‰©ä½™|å‰©é¤˜|è·[ç¦»é›¢]?\S*?(?:ç»“æŸ|çµæŸ|åˆ°æœŸ)?\S*?(?:è¿˜æœ‰|é‚„æœ‰)?)\s*'
                r'(?:(\d+)\s*(?:å¹´|years?))?\s*'
                r'(?:(\d+)\s*(?:æœˆ|ä¸ªæœˆ|å€‹æœˆ|months?))?\s*'
                r'(?:(\d+)\s*(?:å‘¨|é€±|weeks?))?\s*'
                r'(?:(\d+)\s*(?:å¤©|æ—¥|days?))?\s*'
                r'(?:(\d+)\s*(?:å°?æ—¶|å°?æ™‚|hours?|hrs?))?\s*'
                r'(?:(\d+)\s*(?:åˆ†é’Ÿ?|åˆ†é˜?|minutes?|mins?))?',
                re.IGNORECASE
            ),
        ]

        for pattern in patterns:
            match = pattern.search(html)
            if match:
                years = int(match.group(1) or 0)
                months = int(match.group(2) or 0)
                weeks = int(match.group(3) or 0)
                days = int(match.group(4) or 0)
                hours = int(match.group(5) or 0)
                minutes = int(match.group(6) or 0)

                # è‡³å°‘è¦æœ‰ä¸€ä¸ªæ—¶é—´å•ä½
                if years + months + weeks + days + hours + minutes == 0:
                    continue

                # è®¡ç®—ç»“æŸæ—¶é—´
                try:
                    tz = pytz.timezone(settings.TZ)
                    now = datetime.now(tz)
                    end_time = now + timedelta(
                        days=years * 365 + months * 30 + weeks * 7 + days,
                        hours=hours,
                        minutes=minutes
                    )
                    return end_time.strftime('%Y-%m-%d %H:%M:%S')
                except Exception:
                    pass

        return None

    def __merge_metrics(self, table_metrics: List[Dict[str, Any]],
                        text_metrics: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        åˆå¹¶è¡¨æ ¼æŒ‡æ ‡å’Œæ–‡æœ¬æŒ‡æ ‡ï¼Œå»é™¤é‡å¤
        è¡¨æ ¼æŒ‡æ ‡ä¼˜å…ˆï¼ˆé€šå¸¸æ›´å‡†ç¡®ï¼‰
        """
        if not table_metrics:
            return text_metrics
        if not text_metrics:
            return table_metrics

        # ä½¿ç”¨æŒ‡æ ‡åç§°ä½œä¸ºkeyè¿›è¡Œå»é‡
        merged = {self.__normalize_metric_name(m['name']): m for m in table_metrics}

        for metric in text_metrics:
            key = self.__normalize_metric_name(metric['name'])
            if key not in merged:
                merged[key] = metric
            else:
                # è¡¥å……ç¼ºå¤±å­—æ®µ
                existing = merged[key]
                if not existing.get('required') and metric.get('required'):
                    existing['required'] = metric['required']
                if not existing.get('current') and metric.get('current'):
                    existing['current'] = metric['current']
                if existing.get('passed') is None and metric.get('passed') is not None:
                    existing['passed'] = metric['passed']

        return list(merged.values())

    def __normalize_metric_name(self, name: str) -> str:
        """æ ‡å‡†åŒ–æŒ‡æ ‡åç§°ç”¨äºå»é‡æ¯”è¾ƒ"""
        if not name:
            return ''
        # ç§»é™¤ç©ºç™½å’Œæ ‡ç‚¹
        normalized = re.sub(r'[\sï¼š:ï¼š\-_]+', '', name.lower())
        # ç®€ç¹ä½“è½¬æ¢ï¼ˆç®€å•æ›¿æ¢ï¼‰
        replacements = {
            'å‚³': 'ä¼ ', 'ç¨®': 'ç§', 'æ™‚': 'æ—¶', 'é–“': 'é—´',
            'ç©': 'ç§¯', 'æ•¸': 'æ•°', 'æ¨™': 'æ ‡', 'é”': 'è¾¾',
        }
        for trad, simp in replacements.items():
            normalized = normalized.replace(trad, simp)
        return normalized

    def __extract_assessment_name(self, lines: List[str]) -> Tuple[Optional[str], int]:
        """
        æå–è€ƒæ ¸åç§°ï¼ˆæ”¯æŒç®€ç¹ä½“ï¼‰ï¼Œè¿”å›(åç§°, è¡Œç´¢å¼•)
        ä½¿ç”¨å¤šçº§åŒ¹é…ç­–ç•¥ï¼Œä¼˜å…ˆçº§ä»é«˜åˆ°ä½
        """
        # æ’é™¤æ¨¡å¼ï¼šè¿™äº›æ˜¯æç¤ºç”¨æˆ·å¼€å¯è€ƒæ ¸çš„æ–‡æœ¬ï¼Œä¸æ˜¯çœŸæ­£çš„è€ƒæ ¸
        exclude_patterns = [
            re.compile(r'(?:ç”¨æˆ·|ç”¨æˆ¶)?(?:å¼€å¯|é–‹å•Ÿ|å¯åŠ¨|å•Ÿå‹•|è¿›å…¥|é€²å…¥|ç”³è¯·|ç”³è«‹|å‚åŠ |åƒåŠ ).*?è€ƒæ ¸', re.IGNORECASE),
            re.compile(r'è€ƒæ ¸.*?(?:å¼€å¯|é–‹å•Ÿ|å¯åŠ¨|å•Ÿå‹•|ç”³è¯·|ç”³è«‹|å…¥å£|é“¾æ¥|éˆæ¥)', re.IGNORECASE),
            re.compile(r'(?:ç‚¹å‡»|é»æ“Š|click).*?è€ƒæ ¸', re.IGNORECASE),
        ]

        # æ¨¡å¼1ï¼šæ ‡å‡†æ ¼å¼ "åç§°ï¼šxxx" / "è€ƒæ ¸é¡¹ç›®ï¼šxxx" / "ä»»åŠ¡åç§°ï¼šxxx"
        name_patterns = [
            re.compile(r'^å[ç§°ç¨±][ï¼š:]\s*(?P<value>.+)', re.IGNORECASE),
            re.compile(r'(?:è€ƒæ ¸|ä»»[åŠ¡å‹™])?(?:å[ç§°ç¨±å­—]|é¡¹ç›®|é …ç›®)[ï¼š:]\s*(?P<value>.+)', re.IGNORECASE),
            re.compile(r'(?:å½“å‰|ç•¶å‰)?è€ƒæ ¸[ï¼š:]\s*(?P<value>.+)', re.IGNORECASE),
        ]

        # æ¨¡å¼2ï¼šå€’è®¡æ—¶æ ¼å¼ "ç¦»xxxè€ƒæ ¸ç»“æŸè¿˜æœ‰" / "è·xxxç»“æŸ"
        countdown_patterns = [
            re.compile(r'[ç¦»é›¢è·](?P<name>.+?)è€ƒæ ¸(?:ç»“æŸ|çµæŸ)', re.IGNORECASE),
            re.compile(r'[ç¦»é›¢è·](?P<name>.+?)(?:ç»“æŸ|çµæŸ|åˆ°æœŸ)', re.IGNORECASE),
        ]

        # æ¨¡å¼3ï¼šæ ‡é¢˜æ ¼å¼ "ã€xxxè€ƒæ ¸ã€‘" / "[æ–°æ‰‹ä»»åŠ¡]" / "â˜…è€ƒæ ¸ä¿¡æ¯â˜…"
        title_patterns = [
            re.compile(r'[ã€\[ã€Œã€](?P<name>[^ã€‘\]ã€ã€]*?è€ƒæ ¸[^ã€‘\]ã€ã€]*)[ã€‘\]ã€ã€]', re.IGNORECASE),
            re.compile(r'[ã€\[ã€Œã€](?P<name>(?:æ–°æ‰‹|æ–°äºº|å…»æˆ|è©¦ç”¨|è¯•ç”¨|è§‚å¯Ÿ|é¤Šæˆ|è§€å¯Ÿ)[^ã€‘\]ã€ã€]*)[ã€‘\]ã€ã€]', re.IGNORECASE),
            re.compile(r'[â˜…â˜†â–¶â–ºâ—†â—‡](?P<name>[^â˜…â˜†â–¶â–ºâ—†â—‡]*?è€ƒæ ¸[^â˜…â˜†â–¶â–ºâ—†â—‡]*)[â˜…â˜†â–¶â–ºâ—†â—‡]', re.IGNORECASE),
        ]

        # æ¨¡å¼4ï¼šç‹¬ç«‹è€ƒæ ¸ç±»å‹ "æ–°æ‰‹è€ƒæ ¸" / "å…»æˆæœŸ" ç­‰
        standalone_patterns = [
            re.compile(r'^(?P<name>(?:æ–°æ‰‹|æ–°äºº|ä¿[å·è™Ÿ]|æ´»[è·ƒèº]åº¦?|åš[ç§ç¨®]|ä¸Š[ä¼ å‚³]|é­”åŠ›|å…»æˆ|é¤Šæˆ|è¯•ç”¨|è©¦ç”¨|è§‚å¯Ÿ|è§€å¯Ÿ)è€ƒæ ¸)(?:[ï¼š:\s]|$)', re.IGNORECASE),
            re.compile(r'^(?P<name>(?:å…»æˆ|é¤Šæˆ|è¯•ç”¨|è©¦ç”¨|è§‚å¯Ÿ|è§€å¯Ÿ|æ–°æ‰‹|probation|trial)æœŸ?)(?:[ï¼š:\s]|$)', re.IGNORECASE),
        ]

        # æ¨¡å¼5ï¼šåŒ…å«"è€ƒæ ¸"ä¸”æœ‰æŒ‡æ ‡ç‰¹å¾çš„è¡Œ
        assessment_indicator = re.compile(
            r'è€ƒæ ¸.{0,20}(?:æŒ‡[æ ‡æ¨™]|è¦æ±‚|ç›®[æ ‡æ¨™]|ä»»[åŠ¡å‹™])',
            re.IGNORECASE
        )

        for i, line in enumerate(lines):
            # å…ˆæ£€æŸ¥æ˜¯å¦åŒ¹é…æ’é™¤æ¨¡å¼ï¼ˆå¦‚"ç”¨æˆ·å¼€å¯æ–°æ‰‹è€ƒæ ¸"ï¼‰
            if any(pattern.search(line) for pattern in exclude_patterns):
                continue

            # 1. å…ˆå°è¯•æ ‡å‡†åç§°æ ¼å¼
            for pattern in name_patterns:
                match = pattern.search(line)
                if match:
                    value = match.group('value').strip()
                    # å†æ¬¡æ£€æŸ¥æå–çš„å€¼æ˜¯å¦åŒ…å«æ’é™¤å…³é”®è¯
                    if any(pattern.search(value) for pattern in exclude_patterns):
                        continue
                    return value, i

            # 2. å†å°è¯•å€’è®¡æ—¶æ ¼å¼
            for pattern in countdown_patterns:
                match = pattern.search(line)
                if match:
                    name = match.group('name').strip()
                    # å¦‚æœåç§°æœ«å°¾æ²¡æœ‰"è€ƒæ ¸"åˆ™è¡¥å……
                    if not name.endswith(('è€ƒæ ¸', 'ä»»åŠ¡', 'ä»»å‹™', 'æœŸ')):
                        name = f"{name}è€ƒæ ¸"
                    return name, i

            # 3. å°è¯•æ ‡é¢˜æ ¼å¼
            for pattern in title_patterns:
                match = pattern.search(line)
                if match:
                    name = match.group('name').strip()
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«æ’é™¤å…³é”®è¯
                    if any(pattern.search(name) for pattern in exclude_patterns):
                        continue
                    return name, i

            # 4. å°è¯•ç‹¬ç«‹è€ƒæ ¸ç±»å‹
            for pattern in standalone_patterns:
                match = pattern.search(line)
                if match:
                    return match.group('name').strip(), i

        # 5. æœ€åå°è¯•é€šè¿‡æŒ‡æ ‡ç‰¹å¾å®šä½è€ƒæ ¸åŒºå—
        for i, line in enumerate(lines):
            # è·³è¿‡æ’é™¤æ¨¡å¼
            if any(pattern.search(line) for pattern in exclude_patterns):
                continue
            if assessment_indicator.search(line):
                # æå–è€ƒæ ¸ç±»å‹
                type_match = re.search(r'([\u4e00-\u9fa5]+è€ƒæ ¸)', line)
                if type_match:
                    name = type_match.group(1)
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«æ’é™¤å…³é”®è¯
                    if any(pattern.search(name) for pattern in exclude_patterns):
                        continue
                    return name, i
                return "ç«™ç‚¹è€ƒæ ¸", i

        # 6. å¦‚æœä»æœªæ‰¾åˆ°ï¼Œæ£€æŸ¥æ˜¯å¦å­˜åœ¨è€ƒæ ¸å…³é”®è¯
        for i, line in enumerate(lines):
            # è·³è¿‡æ’é™¤æ¨¡å¼
            if any(pattern.search(line) for pattern in exclude_patterns):
                continue
            line_lower = line.lower()
            for keyword in self._ASSESSMENT_KEYWORDS:
                if keyword.lower() in line_lower:
                    # å°è¯•æå–æ›´å…·ä½“çš„åç§°
                    type_match = re.search(r'([\u4e00-\u9fa5]{2,6}(?:è€ƒæ ¸|ä»»åŠ¡|ä»»å‹™|æœŸ))', line)
                    if type_match:
                        return type_match.group(1), i
                    return keyword, i

        return None, 0

    def __extract_time_range(self, lines: List[str]) -> Tuple[Optional[str], Optional[str]]:
        """æå–æ—¶é—´èŒƒå›´ï¼ˆæ”¯æŒç®€ç¹ä½“ï¼‰"""
        # æ—¥æœŸèŒƒå›´æ¨¡å¼
        date_pattern = r'\d{4}[./-]\d{1,2}[./-]\d{1,2}(?:\s+\d{1,2}:\d{2}(?::\d{2})?)?'
        date_range = re.compile(rf'({date_pattern})\s*(?:~|ï½|è‡³|åˆ°|â€”|-)\s*({date_pattern})')

        # æ—¶é—´è§¦å‘å…³é”®è¯ï¼ˆæ”¯æŒç®€ç¹ä½“ï¼‰
        time_triggers = [
            re.compile(r'^[æ—¶æ™‚][é—´é–“][ï¼š:]', re.IGNORECASE),  # "æ—¶é—´ï¼š" å¼€å¤´
            re.compile(r'(?:è€ƒæ ¸)?(?:[æ—¶æ™‚][é—´é–“]|æœŸ[é–“é—´]|å‘¨æœŸ|æœŸé™)', re.IGNORECASE),  # åŸæœ‰æ¨¡å¼
        ]

        for line in lines:
            # æ£€æŸ¥æ˜¯å¦åŒ…å«æ—¶é—´è§¦å‘è¯
            has_trigger = any(trigger.search(line) for trigger in time_triggers)
            if not has_trigger:
                continue

            match = date_range.search(line)
            if match:
                return match.group(1).strip(), match.group(2).strip()

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å¸¦è§¦å‘è¯çš„ï¼Œå°è¯•ç›´æ¥åŒ¹é…æ—¥æœŸèŒƒå›´
        for line in lines:
            match = date_range.search(line)
            if match:
                return match.group(1).strip(), match.group(2).strip()

        return None, None

    def __extract_metrics(self, lines: List[str]) -> List[Dict[str, Any]]:
        """
        æå–è€ƒæ ¸æŒ‡æ ‡ï¼ˆæ”¯æŒç®€ç¹ä½“å’Œå¤šç§æ ¼å¼ï¼‰
        ä½¿ç”¨å¤šé‡åŒ¹é…ç­–ç•¥
        """
        metrics = []

        # æ¨¡å¼1ï¼šæ ‡å‡†æ ¼å¼ "æŒ‡æ ‡1ï¼šä¸Šä¼ é‡"
        metric_header = re.compile(
            r'(?:(?:è€ƒæ ¸)?(?:æŒ‡[æ ‡æ¨™]|é¡¹ç›®|é …ç›®|æ¡ä»¶|æ¢ä»¶))\s*(?P<index>\d+)?[ï¼š:]\s*(?P<name>[^,ï¼Œã€‚ï¼›;]+)',
            re.IGNORECASE
        )

        # æ¨¡å¼2ï¼šç®€å•æ ¼å¼ "ä¸Šä¼ é‡ï¼š å·²é€šè¿‡" æˆ– "åšç§ç§¯åˆ†ï¼š å·²é€šè¿‡"
        # æ”¯æŒæ›´å¤šåç§°åç¼€ï¼šé‡|ç‡|å€¼|æ•°|æ•¸|åˆ†|ç§¯åˆ†|æ™‚é–“|æ—¶é—´|æ—¶é•¿|æ™‚é•·
        simple_metric = re.compile(
            r'^(?P<name>[\u4e00-\u9fa5]{2,8})[ï¼š:]\s*(?P<value>.+)$'
        )

        # æ¨¡å¼3ï¼šåˆ—è¡¨æ ¼å¼ "â€¢ ä¸Šä¼ é‡ 100GB" æˆ– "1. åšç§æ—¶é—´ â‰¥ 100å°æ—¶"
        list_metric = re.compile(
            r'^(?:[â€¢Â·â—â—‹â—†â—‡â˜…â˜†\-\*]|\d+[\.ã€\)])\s*(?P<name>[\u4e00-\u9fa5]{2,8})\s*[:ï¼š]?\s*(?P<value>.+)$'
        )

        # æ¨¡å¼4ï¼šè¿›åº¦æ ¼å¼ "ä¸Šä¼ é‡: 50.5GB / 100GB (50.5%)"
        progress_metric = re.compile(
            r'(?P<name>[\u4e00-\u9fa5]{2,8})\s*[:ï¼š]\s*'
            r'(?P<current>[\d,.]+\s*[A-Za-z]*)\s*/\s*(?P<required>[\d,.]+\s*[A-Za-z]*)'
            r'(?:\s*\((?P<percent>[\d.]+)\s*%\))?',
            re.IGNORECASE
        )

        # æ¨¡å¼5ï¼šçŠ¶æ€æ ¼å¼ "âœ“ ä¸Šä¼ é‡å·²è¾¾æ ‡" æˆ– "âœ— åšç§æ—¶é—´æœªå®Œæˆ"
        status_metric = re.compile(
            r'^(?P<icon>[âœ“âœ”âˆšâ˜‘âœ…âœ—âœ˜Ã—â˜’âŒ])\s*(?P<name>[\u4e00-\u9fa5]{2,8})\s*(?P<status>.*)$'
        )

        # è·³è¿‡çš„è¡Œï¼ˆéæŒ‡æ ‡å†…å®¹ï¼‰
        skip_patterns = [
            r'[ç¦»é›¢è·].+(?:è€ƒæ ¸|ç»“æŸ|çµæŸ)',  # å€’è®¡æ—¶è¡Œ
            r'(?:é€šè¿‡|é€é)æ[èµ è´ˆ]',          # æèµ æç¤º
            r'æ¸©é¦¨æç¤º|æº«é¦¨æç¤º',              # æç¤ºä¿¡æ¯
            r'(?:å¦‚æœ‰|è‹¥æœ‰)(?:ç–‘é—®|ç–‘å•)',    # ç–‘é—®æç¤º
            r'è€ƒæ ¸(?:æ—¶é—´|æ™‚é–“|æœŸé—´|æœŸé–“)',   # æ—¶é—´è¯´æ˜è¡Œ
            r'æ³¨æ„[ï¼š:]',                      # æ³¨æ„æç¤ºè¡Œ
            r'è¯·ä¿æŒ|è«‹ä¿æŒ',                  # ä¿æŒçŠ¶æ€æç¤º
            r'ä¹Ÿå¯ä»¥é€šè¿‡|ä¹Ÿå¯ä»¥é€é',          # å¯é€‰æç¤º
            # ç«™ç‚¹ç»Ÿè®¡
            r'è®¿é—®ç”¨æˆ·|è¨ªå•ç”¨æˆ¶|æ³¨å†Œç”¨æˆ·|è¨»å†Šç”¨æˆ¶',
            r'ä»Šæ—¥è®¿é—®|æœ¬å‘¨è®¿é—®|å½“å‰è®¿é—®',
            r'ç§å­æ€»|ç¸½ä¸Šä¼ |ç¸½ä¸‹è½½|æ€»æ•°æ®',
            r'Peasant|Power User|Elite User|Crazy User|Insane User|Veteran User|Extreme User|Ultimate User|Nexus Master',
            r'è´µå®¾|æèµ è€…|è¢«è­¦å‘Š|è¢«ç¦ç”¨æˆ·',
            r'ç”·ç”Ÿ|å¥³ç”Ÿ',
            r'æ–­ç§|æ–·ç¨®|åŒä¼´|Tracker',
            # ç‰ˆå—/å¸–å­
            r'ç‰ˆ[å—å¡Š]|Feedback|Appeal|Record',
            r'é—®é¢˜åé¦ˆ|å¤‡æ¡ˆ',
            # ç§å­æ ‡é¢˜
            r'\d{4}p|BluRay|WEB-DL|REMUX|H\.26[45]',
            r'å¯¼æ¼”|ä¸»æ¼”|ç±»åˆ«|å­—å¹•',
            # æŠ•ç¥¨
            r'å¼ƒæƒ|æ£„æ¬Š|æ˜¯ï¼Œ|å¦ï¼Œ',
            # å…¬å‘Š
            r'æ‹›è˜|è§£å°|ç”³è¯‰|QQç¾¤|TGç¾¤',
            r'å¼€æ³¨æ—¶é—´|å‘é‚€æ—¶é—´',
        ]
        skip_re = re.compile('|'.join(skip_patterns), re.IGNORECASE)

        current_metric = None
        for line in lines:
            # è·³è¿‡URL
            if '://' in line or line.startswith('http'):
                continue
            # è·³è¿‡ç‰¹å®šæ¨¡å¼çš„è¡Œ
            if skip_re.search(line):
                continue

            # 1. å…ˆå°è¯•è¿›åº¦æ ¼å¼ï¼ˆæœ€ç²¾ç¡®ï¼‰
            progress_match = progress_metric.search(line)
            if progress_match and self.__is_metric_name(progress_match.group('name')):
                if current_metric:
                    metrics.append(current_metric)
                    current_metric = None

                name = progress_match.group('name').strip()
                current = progress_match.group('current').strip()
                required = progress_match.group('required').strip()

                # è®¡ç®—æ˜¯å¦é€šè¿‡
                cur_val = self.__parse_metric_value(current)
                req_val = self.__parse_metric_value(required)
                passed = cur_val >= req_val if cur_val is not None and req_val is not None and req_val > 0 else None

                metrics.append({
                    'name': name,
                    'index': None,
                    'required': required,
                    'current': current,
                    'passed': passed,
                })
                continue

            # 2. å°è¯•çŠ¶æ€æ ¼å¼
            status_match = status_metric.match(line)
            if status_match and self.__is_metric_name(status_match.group('name')):
                if current_metric:
                    metrics.append(current_metric)
                    current_metric = None

                icon = status_match.group('icon')
                name = status_match.group('name').strip()
                status_text = status_match.group('status').strip()

                passed = icon in 'âœ“âœ”âˆšâ˜‘âœ…'
                metrics.append({
                    'name': name,
                    'index': None,
                    'required': None,
                    'current': status_text if status_text else ('å·²é€šè¿‡' if passed else 'æœªé€šè¿‡'),
                    'passed': passed,
                })
                continue

            # 3. å°è¯•æ ‡å‡†æ ¼å¼
            header_match = metric_header.search(line)
            if header_match:
                if current_metric:
                    metrics.append(current_metric)
                current_metric = {
                    'name': header_match.group('name').strip(),
                    'index': int(header_match.group('index')) if header_match.group('index') else None,
                    'required': None,
                    'current': None,
                    'passed': None,
                }
                remainder = line[header_match.end():]
                self.__parse_metric_details(current_metric, remainder)
                continue

            # 4. å°è¯•åˆ—è¡¨æ ¼å¼
            list_match = list_metric.match(line)
            if list_match and self.__is_metric_name(list_match.group('name')):
                if current_metric:
                    metrics.append(current_metric)
                    current_metric = None

                metric = self.__parse_simple_metric(
                    list_match.group('name'),
                    list_match.group('value')
                )
                if metric:
                    metrics.append(metric)
                continue

            # 5. å°è¯•ç®€å•æ ¼å¼
            simple_match = simple_metric.match(line)
            if simple_match and self.__is_metric_name(simple_match.group('name')):
                if current_metric:
                    metrics.append(current_metric)
                    current_metric = None

                metric = self.__parse_simple_metric(
                    simple_match.group('name'),
                    simple_match.group('value')
                )
                if metric:
                    metrics.append(metric)
                continue

            # 6. ç»§ç»­è§£æå½“å‰æŒ‡æ ‡è¯¦æƒ…
            if current_metric:
                self.__parse_metric_details(current_metric, line)

        if current_metric:
            metrics.append(current_metric)

        # è¿‡æ»¤æ— æ•ˆæŒ‡æ ‡
        valid_metrics = [m for m in metrics if m.get('name') and (m.get('current') or m.get('required') or m.get('passed') is not None)]

        return valid_metrics

    def __parse_simple_metric(self, name: str, value: str) -> Optional[Dict[str, Any]]:
        """è§£æç®€å•æ ¼å¼æŒ‡æ ‡ï¼ˆå¦‚"ä¸Šä¼ é‡ï¼š å·²é€šè¿‡"æˆ–"ä¸Šä¼ é‡ï¼š è¿˜éœ€è¦ 97.60 GB"ï¼‰"""
        # éªŒè¯æŒ‡æ ‡åç§°
        if not self.__is_metric_name(name):
            return None

        # éªŒè¯æŒ‡æ ‡å€¼
        if not self.__is_valid_metric_value(value):
            return None

        metric = {
            'name': name.strip(),
            'index': None,
            'required': None,
            'current': None,
            'passed': None,
        }

        value = value.strip()

        # æ£€æŸ¥æ˜¯å¦å·²é€šè¿‡
        if re.search(r'å·²é€šè¿‡|é€šé|åˆæ ¼|é”æ¨™|è¾¾æ ‡', value):
            metric['passed'] = True
            metric['current'] = 'å·²é€šè¿‡'
            return metric

        # æ£€æŸ¥æ˜¯å¦è¿˜éœ€è¦
        need_match = re.search(r'(?:è¿˜éœ€è¦|é‚„éœ€è¦|ä»éœ€|éœ€å†?)\s*([\d.]+)\s*([A-Za-z]+)?', value)
        if need_match:
            metric['passed'] = False
            metric['current'] = f"è¿˜éœ€ {need_match.group(1)} {need_match.group(2) or ''}".strip()
            return metric

        # æ£€æŸ¥æ˜¯å¦æœªé€šè¿‡
        if re.search(r'æœªé€šè¿‡|æœªé€šé|ä¸åˆæ ¼|æœªé”æ¨™|æœªè¾¾æ ‡', value):
            metric['passed'] = False
            metric['current'] = 'æœªé€šè¿‡'
            return metric

        # æ£€æŸ¥"å½“å‰å€¼ / è¦æ±‚å€¼"æ ¼å¼ï¼ˆå¦‚"0.00 KB / 100.00 GB"æˆ–"548 / 10000"ï¼‰
        ratio_match = re.search(
            r'([\d,.]+)\s*([A-Za-z]*)\s*/\s*([\d,.]+)\s*([A-Za-z]*)',
            value
        )
        if ratio_match:
            current_val = ratio_match.group(1)
            current_unit = ratio_match.group(2) or ''
            required_val = ratio_match.group(3)
            required_unit = ratio_match.group(4) or ''

            metric['current'] = f"{current_val} {current_unit}".strip()
            metric['required'] = f"{required_val} {required_unit}".strip()

            # ä½¿ç”¨å•ä½è½¬æ¢è¿›è¡Œæ­£ç¡®æ¯”è¾ƒ
            cur_parsed = self.__parse_metric_value(metric['current'])
            req_parsed = self.__parse_metric_value(metric['required'])

            if cur_parsed is not None and req_parsed is not None and req_parsed > 0:
                metric['passed'] = cur_parsed >= req_parsed
            else:
                # å¦‚æœæ— æ³•è§£æå¸¦å•ä½å€¼ï¼Œå°è¯•ç›´æ¥æ¯”è¾ƒæ•°å­—
                try:
                    cur_num = float(current_val.replace(',', ''))
                    req_num = float(required_val.replace(',', ''))
                    metric['passed'] = cur_num >= req_num
                except ValueError:
                    metric['passed'] = None
            return metric

        return None

    def __should_preserve_comma(self, metric_name: str) -> bool:
        """
        åˆ¤æ–­æŒ‡æ ‡æ˜¯å¦éœ€è¦ä¿ç•™è‹±æ–‡é€—å·ï¼ˆåƒåˆ†ä½ï¼‰
        ä¸»è¦é’ˆå¯¹å¯èƒ½åŒ…å«å¤§æ•°å€¼çš„æ—¶é—´ç±»æŒ‡æ ‡
        """
        if not metric_name:
            return False

        # éœ€è¦ä¿ç•™åƒåˆ†ä½é€—å·çš„æŒ‡æ ‡å…³é”®è¯
        preserve_keywords = (
            'åšç§æ—¶é—´', 'åšç¨®æ™‚é–“', 'ä¿ç§æ—¶é—´', 'ä¿ç¨®æ™‚é–“',
            'åšç§æ—¶é•¿', 'åšç¨®æ™‚é•·', 'å¹³å‡åšç§', 'å¹³å‡åšç¨®',
            'seed time', 'seeding time', 'average seed'
        )

        name_lower = metric_name.lower()
        for keyword in preserve_keywords:
            if keyword.lower() in name_lower or keyword in metric_name:
                return True

        return False

    def __parse_metric_details(self, metric: Dict[str, Any], text: str) -> None:
        """è§£ææŒ‡æ ‡è¯¦æƒ…ï¼ˆè¦æ±‚ã€å½“å‰å€¼ã€ç»“æœï¼‰"""
        # åˆ¤æ–­å½“å‰æŒ‡æ ‡æ˜¯å¦éœ€è¦ä¿ç•™è‹±æ–‡é€—å·
        preserve_comma = self.__should_preserve_comma(metric.get('name', ''))

        if preserve_comma:
            # å¯¹äºæ—¶é—´ç±»æŒ‡æ ‡ï¼šåªåœ¨ä¸­æ–‡é€—å·"ï¼Œ"å¤„åˆ†éš”ï¼Œè‹±æ–‡é€—å·","ä¿ç•™ï¼ˆç”¨äºåƒåˆ†ä½æ•°å­—å¦‚ "3,202.78"ï¼‰
            # è§£æè¦æ±‚å€¼
            if not metric.get('required'):
                req_match = re.search(
                    r'(?:è¦æ±‚|éœ€è¦|ç›®æ¨™|ç›®æ ‡|æ¨™æº–|æ ‡å‡†)[ï¼š:]\s*(?P<value>[^ï¼Œ]+?)(?=\s*(?:ï¼Œ\s*)?(?:å½“å‰|ç•¶å‰|ç›®å‰|çµæœ|ç»“æœ)|$)',
                    text
                )
                if req_match:
                    metric['required'] = req_match.group('value').strip()

            # è§£æå½“å‰å€¼
            if not metric.get('current'):
                cur_match = re.search(
                    r'(?:å½“å‰|ç•¶å‰|ç›®å‰)[ï¼š:]\s*(?P<value>[^ï¼Œ]+?)(?=\s*(?:ï¼Œ\s*)?(?:çµæœ|ç»“æœ|è¦æ±‚)|$)',
                    text
                )
                if cur_match:
                    metric['current'] = cur_match.group('value').strip()

            # è§£æç»“æœ
            if metric.get('passed') is None:
                result_match = re.search(r'(?:çµæœ|ç»“æœ)[ï¼š:]\s*(?P<value>[^ï¼Œ]+)', text)
                if result_match:
                    result_text = result_match.group('value').strip()
                    metric['passed'] = self.__interpret_status(result_text)
                else:
                    passed = self.__interpret_status(text)
                    if passed is not None:
                        metric['passed'] = passed
        else:
            # å¯¹äºå…¶ä»–æŒ‡æ ‡ï¼šæŒ‰ä¸­è‹±æ–‡é€—å·ã€åˆ†å·åˆ†å‰²ï¼ˆä¼ ç»Ÿé€»è¾‘ï¼‰
            chunks = re.split(r'[ï¼Œ,ï¼›;]+', text)

            for chunk in chunks:
                chunk = chunk.strip()
                if not chunk:
                    continue

                # è§£æè¦æ±‚å€¼
                if not metric.get('required'):
                    req_match = re.search(r'(?:è¦æ±‚|éœ€è¦|ç›®æ¨™|ç›®æ ‡|æ¨™æº–|æ ‡å‡†)[ï¼š:]\s*(?P<value>.+)', chunk)
                    if req_match:
                        metric['required'] = req_match.group('value').strip()
                        continue

                # è§£æå½“å‰å€¼
                if not metric.get('current'):
                    cur_match = re.search(r'(?:å½“å‰|ç•¶å‰|ç›®å‰)[ï¼š:]\s*(?P<value>.+)', chunk)
                    if cur_match:
                        metric['current'] = cur_match.group('value').strip()
                        continue

                # è§£æç»“æœ
                if metric.get('passed') is None:
                    result_match = re.search(r'(?:çµæœ|ç»“æœ)[ï¼š:]\s*(?P<value>.+)', chunk)
                    if result_match:
                        result_text = result_match.group('value').strip()
                        metric['passed'] = self.__interpret_status(result_text)
                        continue

            # å¦‚æœæ²¡æœ‰æ˜¾å¼ç»“æœï¼Œå°è¯•ä»æ•´ä¸ªæ–‡æœ¬è§£æçŠ¶æ€
            if metric.get('passed') is None:
                passed = self.__interpret_status(text)
                if passed is not None:
                    metric['passed'] = passed

    def __interpret_status(self, text: str) -> Optional[bool]:
        """
        è§£æçŠ¶æ€æ–‡æœ¬ï¼Œè¿”å›æ˜¯å¦é€šè¿‡
        æ”¯æŒï¼šçŠ¶æ€å…³é”®è¯ã€å›¾æ ‡ã€ç™¾åˆ†æ¯”
        """
        if not text:
            return None

        # æ¸…ç†æ–‡æœ¬
        cleaned = re.sub(r'[ï¼!ã€‚ï¼\.]+$', '', text.strip())

        # 1. é¦–å…ˆæ£€æŸ¥å›¾æ ‡ï¼ˆæœ€å¯é ï¼‰
        for icon, passed in self._STATUS_ICONS.items():
            if icon in cleaned:
                return passed

        # 2. æ£€æŸ¥ç™¾åˆ†æ¯”ï¼ˆ100%åŠä»¥ä¸Šè¡¨ç¤ºé€šè¿‡ï¼‰
        percent_match = re.search(r'(\d+(?:\.\d+)?)\s*%', cleaned)
        if percent_match:
            percent = float(percent_match.group(1))
            if percent >= 100:
                return True
            # å¦‚æœåªæœ‰ç™¾åˆ†æ¯”ï¼Œ0%è¡¨ç¤ºæœªé€šè¿‡
            if percent == 0 and len(cleaned.strip()) < 10:
                return False

        # 3. æ£€æŸ¥çŠ¶æ€å…³é”®è¯ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼šå¦å®šè¯å…ˆæ£€æŸ¥ï¼‰
        # ä½¿ç”¨æ›´å®½æ¾çš„åŒ¹é…ï¼Œå…è®¸å‰åæœ‰å…¶ä»–å­—ç¬¦
        for keyword, passed in self._STATUS_KEYWORDS.items():
            if keyword in cleaned.lower() if keyword.isascii() else keyword in cleaned:
                return passed

        return None

    def __build_assessment_result(self, site_id: int, site_name: str,
                                   assessment: Dict) -> Optional[Dict[str, Any]]:
        """æ ¹æ®æŠ“å–çš„è€ƒæ ¸ä¿¡æ¯æ„å»ºç»“æœï¼Œå¦‚æœè€ƒæ ¸æ— æ•ˆåˆ™è¿”å›None"""
        metrics = assessment.get('metrics', [])

        # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„æŒ‡æ ‡æ•°æ®
        # å¦‚æœæ‰€æœ‰æŒ‡æ ‡çš„å½“å‰å€¼éƒ½æ˜¯æ— æ•ˆçš„ï¼ˆå¦‚ "-", ç©º, æˆ–æ— æ•°æ®ï¼‰ï¼Œåˆ™è®¤ä¸ºæ²¡æœ‰çœŸæ­£çš„è€ƒæ ¸
        valid_metric_count = 0
        for m in metrics:
            current = m.get('current', '')
            # æ£€æŸ¥å½“å‰å€¼æ˜¯å¦æœ‰æ•ˆï¼ˆéç©ºã€é"-"ã€éçº¯ç¬¦å·ï¼‰
            if current and current.strip() not in ['-', '--', 'â€”', '']:
                # æ£€æŸ¥æ˜¯å¦åŒ…å«æ•°å­—æˆ–çŠ¶æ€å…³é”®è¯
                if re.search(r'\d|å·²é€šè¿‡|é€šé|åˆæ ¼|æœªé€šè¿‡|æœªé€šé|ä¸åˆæ ¼', current):
                    valid_metric_count += 1

        # å¦‚æœæ²¡æœ‰ä»»ä½•æœ‰æ•ˆæŒ‡æ ‡æ•°æ®ï¼Œåˆ™è®¤ä¸ºè¿™ä¸æ˜¯çœŸæ­£çš„è€ƒæ ¸
        if valid_metric_count == 0 and metrics:
            logger.debug(f"ç«™ç‚¹ {site_name} è€ƒæ ¸æŒ‡æ ‡æ— æœ‰æ•ˆæ•°æ®ï¼Œè·³è¿‡")
            return None

        # é‡æ–°è®¡ç®—æœªç¡®å®šçš„passedçŠ¶æ€
        for m in metrics:
            if m.get('passed') is None:
                # å°è¯•ä»currentå€¼è§£æçŠ¶æ€
                if m.get('current'):
                    status = self.__interpret_status(m['current'])
                    if status is not None:
                        m['passed'] = status
                        continue

                # å°è¯•é€šè¿‡æ•°å€¼æ¯”è¾ƒåˆ¤æ–­
                if m.get('current') and m.get('required'):
                    cur_val = self.__parse_metric_value(m['current'])
                    req_val = self.__parse_metric_value(m['required'])
                    if cur_val is not None and req_val is not None and req_val > 0:
                        m['passed'] = cur_val >= req_val

        # ç»Ÿè®¡é€šè¿‡çš„æŒ‡æ ‡æ•°é‡
        passed_count = sum(1 for m in metrics if m.get('passed') is True)
        failed_count = sum(1 for m in metrics if m.get('passed') is False)
        total_count = len(metrics)

        # è®¡ç®—è¿›åº¦ï¼ˆåŸºäºå®é™…å€¼çš„æ¯”ä¾‹ï¼‰
        if total_count > 0:
            progress_values = []
            for m in metrics:
                metric_progress = self.__calculate_metric_progress_value(
                    m.get('current', '0'),
                    m.get('required', '0'),
                    m.get('passed')  # ä¼ é€’ passed çŠ¶æ€ç”¨äºè¾…åŠ©è®¡ç®—
                )
                progress_values.append(metric_progress)
            progress = sum(progress_values) / len(progress_values)
        else:
            progress = 0

        # è®¡ç®—å‰©ä½™å¤©æ•°
        remaining_days = None
        end_time = assessment.get('end_time')
        if end_time:
            remaining_days = self.__parse_remaining_days(end_time, site_name)

        # åˆ¤æ–­çŠ¶æ€
        # ä¼˜å…ˆçº§ï¼šå·²å®Œæˆ > å·²è¿‡æœŸ > è€ƒæ ¸ä¸­
        # æ³¨æ„ï¼šè€ƒæ ¸æœŸé—´æŒ‡æ ‡æœªè¾¾æ ‡ä¸ç®—å¤±è´¥ï¼Œåªæœ‰è¿‡æœŸåæ‰ç®—å¤±è´¥
        if passed_count == total_count and total_count > 0:
            status = 'completed'
        elif remaining_days is not None and remaining_days < 0:
            # å·²è¿‡æœŸï¼šæœ‰æœªé€šè¿‡æŒ‡æ ‡åˆ™å¤±è´¥ï¼Œå…¨éƒ¨é€šè¿‡åˆ™å®Œæˆ
            status = 'failed' if failed_count > 0 else 'completed'
        else:
            # è€ƒæ ¸ä¸­ï¼ˆè¿˜æœ‰æ—¶é—´ï¼Œç»§ç»­åŠªåŠ›ï¼‰
            status = 'in_progress'

        # æ„å»ºæ¶ˆæ¯ï¼ˆåªæ˜¾ç¤ºè€ƒæ ¸å†…å®¹ï¼‰
        msg_parts = [f"[{assessment.get('name', 'è€ƒæ ¸')}]"]
        for m in metrics:
            passed = m.get('passed')
            if passed is True:
                icon = "âœ“"
            elif passed is False:
                icon = "âœ—"
            else:
                icon = "?"

            current = m.get('current') or '-'
            required = m.get('required') or '-'
            msg_parts.append(f"{m['name']}: {current}/{required} {icon}")

        return {
            'site_id': site_id,
            'site_name': site_name,
            'status': status,
            'progress': progress,
            'remaining_days': remaining_days,
            'message': ' | '.join(msg_parts)
        }

    @staticmethod
    def __calculate_registered_days(join_at: str) -> Optional[int]:
        """æ ¹æ®åŠ å…¥æ—¶é—´è®¡ç®—æ³¨å†Œå¤©æ•°"""
        if not join_at:
            return None
        try:
            # å°è¯•å¤šç§æ—¥æœŸæ ¼å¼
            for fmt in ['%Y-%m-%d', '%Y-%m-%d %H:%M:%S', '%Y/%m/%d']:
                try:
                    join_date = datetime.strptime(join_at.split()[0], fmt.split()[0])
                    return (datetime.now() - join_date).days
                except ValueError:
                    continue
            return None
        except Exception:
            return None

    @staticmethod
    def __is_newbie_level(user_level: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºæ–°ç”¨æˆ·/è€ƒæ ¸æœŸç­‰çº§"""
        if not user_level:
            return False
        # å¸¸è§çš„æ–°ç”¨æˆ·ç­‰çº§å…³é”®è¯
        newbie_keywords = [
            'æ–°', 'new', 'trial', 'è¯•ç”¨', 'è€ƒæ ¸',
            'peasant', 'user', 'å­¦å‘˜', 'è§ä¹ '
        ]
        level_lower = user_level.lower()
        return any(kw in level_lower for kw in newbie_keywords)

    def __parse_metric_value(self, value_str: str) -> Optional[float]:
        """
        è§£ææŒ‡æ ‡æ•°å€¼ï¼Œæ”¯æŒå¤šç§å•ä½
        ç»Ÿä¸€è½¬æ¢ä¸ºæ ‡å‡†å•ä½è¿›è¡Œæ¯”è¾ƒï¼š
        - æ–‡ä»¶å¤§å°: è½¬ä¸ºå­—èŠ‚ (bytes)
        - æ—¶é—´: è½¬ä¸ºå°æ—¶ (hours)
        - æ¯”ç‡: ä¿æŒåŸå€¼
        - é­”åŠ›/ç§¯åˆ†: ä¿æŒåŸå€¼

        ä¾‹å¦‚:
        - "3.00 GB" -> 3221225472.0 (å­—èŠ‚)
        - "100 å°æ—¶" -> 100.0 (å°æ—¶)
        - "7 å¤©" -> 168.0 (å°æ—¶)
        - "1.5" (æ¯”ç‡) -> 1.5
        - "10,000" (ç§¯åˆ†) -> 10000.0
        """
        if not value_str:
            return None

        value_str = value_str.strip()

        # æ£€æŸ¥æ˜¯å¦æ˜¯çŠ¶æ€æ–‡æœ¬
        if self.__interpret_status(value_str) is not None:
            return None

        # ç§»é™¤å¸¸è§å‰ç¼€ç¬¦å·
        prefixes = [
            'â‰¥', '>=', '>', 'â‰¤', '<=', '<',
            'ä¸å°‘äº', 'è‡³å°‘', 'æœ€å°‘', 'ä¸ä½äº', 'ä¸å°‘æ–¼', 'è‡³å°‘', 'æœ€å°‘', 'ä¸ä½æ–¼',
            'éœ€è¦', 'éœ€é”', 'éœ€è¾¾', 'è¦æ±‚',
            'è¿˜éœ€', 'é‚„éœ€', 'ä»éœ€',
        ]
        for prefix in prefixes:
            if value_str.startswith(prefix):
                value_str = value_str[len(prefix):].strip()
                break

        # å°è¯•è§£æå¤åˆæ—¶é—´æ ¼å¼ "Xå¤©Yå°æ—¶Zåˆ†é’Ÿ"
        compound_time = self.__parse_compound_time(value_str)
        if compound_time is not None:
            return compound_time

        # åŒ¹é…æ•°å€¼å’Œå•ä½
        # æ”¯æŒæ ¼å¼: "100", "100.5", "1,000", "100 GB", "100GB", "100 å°æ—¶"
        match = re.search(r'([\d,.]+)\s*([A-Za-z\u4e00-\u9fa5]*)', value_str)
        if not match:
            return None

        try:
            # è§£ææ•°å€¼éƒ¨åˆ†
            num_str = match.group(1).replace(',', '')
            num_value = float(num_str)

            # è§£æå•ä½éƒ¨åˆ†
            unit_str = match.group(2).strip() if match.group(2) else ''

            if not unit_str:
                return num_value

            unit_upper = unit_str.upper()

            # æ£€æŸ¥æ˜¯å¦æ˜¯æ–‡ä»¶å¤§å°å•ä½
            if unit_upper in self._SIZE_UNITS:
                return num_value * self._SIZE_UNITS[unit_upper]

            # æ£€æŸ¥æ˜¯å¦æ˜¯æ—¶é—´å•ä½
            if unit_str in self._TIME_UNITS:
                return num_value * self._TIME_UNITS[unit_str]
            if unit_upper in self._TIME_UNITS:
                return num_value * self._TIME_UNITS[unit_upper]

            # æ£€æŸ¥ä¸­æ–‡å•ä½
            for time_unit, multiplier in self._TIME_UNITS.items():
                if time_unit in unit_str:
                    return num_value * multiplier

            # æœªçŸ¥å•ä½ï¼Œè¿”å›åŸå€¼
            return num_value

        except (ValueError, TypeError):
            return None

    def __parse_compound_time(self, value_str: str) -> Optional[float]:
        """
        è§£æå¤åˆæ—¶é—´æ ¼å¼
        æ”¯æŒ: "3å¤©5å°æ—¶", "1å‘¨2å¤©", "100å°æ—¶30åˆ†é’Ÿ"
        è¿”å›: å°æ—¶æ•°
        """
        # å¤åˆæ—¶é—´æ¨¡å¼
        pattern = re.compile(
            r'(?:(\d+)\s*(?:å¹´|years?))?\s*'
            r'(?:(\d+)\s*(?:æœˆ|ä¸ªæœˆ|å€‹æœˆ|months?))?\s*'
            r'(?:(\d+)\s*(?:å‘¨|é€±|weeks?))?\s*'
            r'(?:(\d+)\s*(?:å¤©|æ—¥|days?))?\s*'
            r'(?:(\d+)\s*(?:å°?æ—¶|å°?æ™‚|hours?|hrs?))?\s*'
            r'(?:(\d+)\s*(?:åˆ†é’Ÿ?|åˆ†é˜?|minutes?|mins?))?',
            re.IGNORECASE
        )

        match = pattern.match(value_str)
        if not match:
            return None

        years = int(match.group(1) or 0)
        months = int(match.group(2) or 0)
        weeks = int(match.group(3) or 0)
        days = int(match.group(4) or 0)
        hours = int(match.group(5) or 0)
        minutes = int(match.group(6) or 0)

        # è‡³å°‘è¦æœ‰ä¸¤ä¸ªæ—¶é—´å•ä½æ‰è®¤ä¸ºæ˜¯å¤åˆæ—¶é—´
        units_count = sum(1 for v in [years, months, weeks, days, hours, minutes] if v > 0)
        if units_count < 2:
            return None

        # è½¬æ¢ä¸ºå°æ—¶
        total_hours = (
            years * 365 * 24 +
            months * 30 * 24 +
            weeks * 7 * 24 +
            days * 24 +
            hours +
            minutes / 60
        )

        return total_hours if total_hours > 0 else None

    def __detect_metric_type(self, name: str) -> str:
        """
        æ£€æµ‹æŒ‡æ ‡ç±»å‹ï¼Œç”¨äºç¡®å®šæ•°å€¼æ¯”è¾ƒæ–¹å¼
        è¿”å›: 'size' (æ–‡ä»¶å¤§å°), 'time' (æ—¶é—´), 'ratio' (æ¯”ç‡), 'count' (æ•°é‡)
        """
        name_lower = name.lower()

        # æ£€æŸ¥å„ç±»å‹å…³é”®è¯
        for metric_type, keywords in self._METRIC_KEYWORDS.items():
            for kw in keywords:
                if kw.lower() in name_lower:
                    if metric_type in ('upload', 'download', 'seedsize'):
                        return 'size'
                    elif metric_type in ('seedtime', 'time'):
                        return 'time'
                    elif metric_type == 'ratio':
                        return 'ratio'
                    else:
                        return 'count'

        return 'count'  # é»˜è®¤ä¸ºæ•°é‡ç±»å‹

    def __calculate_metric_progress_value(self, current_str: str, required_str: str,
                                          passed: Optional[bool] = None) -> float:
        """
        è®¡ç®—å•ä¸ªæŒ‡æ ‡çš„è¿›åº¦å€¼
        è¿”å› 0.0 ~ 1.0 ä¹‹é—´çš„è¿›åº¦å€¼

        å‚æ•°:
        - current_str: å½“å‰å€¼å­—ç¬¦ä¸²
        - required_str: è¦æ±‚å€¼å­—ç¬¦ä¸²
        - passed: æ˜¯å¦é€šè¿‡çš„çŠ¶æ€ï¼ˆå¯é€‰ï¼‰
        """
        # 1. å¦‚æœå·²çŸ¥é€šè¿‡çŠ¶æ€ï¼Œä¼˜å…ˆä½¿ç”¨
        if passed is True:
            return 1.0  # å·²é€šè¿‡ = 100%

        # 2. å°è¯•è§£ææ•°å€¼è®¡ç®—è¿›åº¦
        current = self.__parse_metric_value(current_str)
        required = self.__parse_metric_value(required_str)

        if current is not None and required is not None and required > 0:
            # æ­£å¸¸è®¡ç®—è¿›åº¦
            progress = current / required
            return min(progress, 1.0)

        # 3. å¦‚æœæ— æ³•è®¡ç®—ä½†å·²çŸ¥æœªé€šè¿‡ï¼Œç»™ä¸€ä¸ªä¼°ç®—å€¼
        if passed is False:
            # å°è¯•ä»"è¿˜éœ€ X"æå–å‰©ä½™é‡æ¥ä¼°ç®—è¿›åº¦
            if current is not None and current > 0:
                # æœ‰å‰©ä½™é‡æ•°æ®ï¼Œè¯´æ˜æœ‰ä¸€å®šè¿›åº¦ä½†æœªå®Œæˆ
                # ç²—ç•¥ä¼°ç®—ï¼šå‡è®¾å‰©ä½™é‡å æ€»é‡çš„ä¸€éƒ¨åˆ†
                return 0.3  # æœªé€šè¿‡æ—¶ç»™ 30% ä½œä¸ºä¼°ç®—
            return 0.1  # å®Œå…¨æ— è¿›åº¦æ—¶ç»™ 10%

        # 4. çŠ¶æ€æœªçŸ¥ä¸”æ— æ³•è®¡ç®—ï¼Œè¿”å›0
        return 0.0

    def __parse_remaining_days(self, end_time: str, site_name: str) -> Optional[int]:
        """
        è§£æç»“æŸæ—¶é—´å¹¶è®¡ç®—å‰©ä½™å¤©æ•°
        æ”¯æŒå¤šç§æ—¥æœŸæ ¼å¼ï¼Œä½¿ç”¨æ—¶åŒºæ„ŸçŸ¥çš„è®¡ç®—
        """
        if not end_time:
            return None

        # æ ‡å‡†åŒ–æ—¥æœŸåˆ†éš”ç¬¦
        normalized_time = end_time.strip().replace('/', '-')

        # å°è¯•å¤šç§æ—¥æœŸæ ¼å¼
        end_dt = None
        for fmt in self._DATETIME_FORMATS:
            try:
                end_dt = datetime.strptime(normalized_time, fmt)
                break
            except ValueError:
                continue

        if not end_dt:
            logger.warning(f"ç«™ç‚¹ {site_name} æ—¶é—´è§£æå¤±è´¥: {end_time}")
            return None

        # ä½¿ç”¨æ—¶åŒºæ„ŸçŸ¥çš„è®¡ç®—
        try:
            tz = pytz.timezone(settings.TZ)
            end_dt_aware = tz.localize(end_dt)
            now_aware = datetime.now(tz)
            # ç›´æ¥è®¡ç®—æ—¶åŒºæ„ŸçŸ¥çš„æ—¶é—´å·®
            delta = end_dt_aware - now_aware
        except Exception:
            # æ—¶åŒºå¤„ç†å¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°æ—¶é—´
            delta = end_dt - datetime.now()

        remaining = delta.days

        # å¦‚æœè¿˜æœ‰å‰©ä½™æ—¶é—´ï¼Œç®—ä½œå¤šä¸€å¤©
        if delta.seconds > 0 and remaining >= 0:
            remaining += 1

        logger.debug(f"ç«™ç‚¹ {site_name} ç»“æŸæ—¶é—´: {end_time}, å‰©ä½™: {remaining}å¤©")
        return remaining

    @eventmanager.register(EventType.PluginAction)
    def handle_plugin_action(self, event: Event):
        """å¤„ç†æ’ä»¶åŠ¨ä½œäº‹ä»¶"""
        if not event:
            return
        event_data = event.event_data
        if not event_data or event_data.get("action") != "site_assessment":
            return
        self.__refresh_assessment()
